{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Simple objective: branin with sleeps to emulate delay"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# silence TF warnings and info messages, only print errors\n",
    "# https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def objective(points):\n",
    "    if points.shape[1] != 2:\n",
    "        raise ValueError(f\"Incorrect input shape, expected (*, 2), got {x.shape}\")\n",
    "\n",
    "    def branin(x):\n",
    "        x0 = x[..., :1] * 15.0 - 5.0\n",
    "        x1 = x[..., 1:] * 15.0\n",
    "\n",
    "        b = 5.1 / (4 * math.pi ** 2)\n",
    "        c = 5 / math.pi\n",
    "        r = 6\n",
    "        s = 10\n",
    "        t = 1 / (8 * math.pi)\n",
    "        scale = 1\n",
    "        translate = 10\n",
    "\n",
    "        return scale * ((x1 - b * x0 ** 2 + c * x0 - r) ** 2 + s * (1 - t) * np.cos(x0) + translate)\n",
    "        \n",
    "    observations = []\n",
    "    for point in points:\n",
    "        observation = branin(point)\n",
    "        observations.append(observation)\n",
    "    \n",
    "    return observations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "objective(np.array([[0.1, 0.5]]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([32.96369168])]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Here comes Trieste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from trieste.objectives.utils import mk_observer\n",
    "from trieste.space import Box\n",
    "\n",
    "search_space = Box([0, 0], [1, 1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from trieste.data import Dataset\n",
    "\n",
    "num_initial_points = 3\n",
    "initial_query_points = search_space.sample(num_initial_points)\n",
    "initial_observations = objective(initial_query_points.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "initial_data = Dataset(query_points=initial_query_points, observations=tf.constant(initial_observations, dtype=tf.float64))\n",
    "\n",
    "print(initial_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset(query_points=<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
      "array([[0.05866792, 0.08743693],\n",
      "       [0.65182824, 0.57646759],\n",
      "       [0.97908318, 0.87241814]])>, observations=<tf.Tensor: shape=(3, 1), dtype=float64, numpy=\n",
      "array([[185.22940936],\n",
      "       [ 63.94383844],\n",
      "       [108.50778776]])>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import gpflow\n",
    "from trieste.models import create_model\n",
    "from trieste.utils import map_values\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from trieste.models.gpflow.config import GPflowModelConfig\n",
    "\n",
    "\n",
    "def build_model(data):\n",
    "    variance = tf.math.reduce_variance(data.observations)\n",
    "    kernel = gpflow.kernels.RBF(variance=variance)\n",
    "    gpr = gpflow.models.GPR(data.astuple(), kernel, noise_variance=1e-5)\n",
    "    gpflow.set_trainable(gpr.likelihood, False)\n",
    "\n",
    "    return GPflowModelConfig(**{\n",
    "        \"model\": gpr,\n",
    "        \"optimizer\": gpflow.optimizers.Scipy(),\n",
    "        \"optimizer_args\": {\n",
    "            \"minimize_args\": {\"options\": dict(maxiter=100)},\n",
    "        },\n",
    "    })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model_spec = build_model(initial_data)\n",
    "model = create_model(model_spec)\n",
    "\n",
    "model.optimize(initial_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from trieste.acquisition import LocalPenalizationAcquisitionFunction\n",
    "from trieste.acquisition.rule import EfficientGlobalOptimization\n",
    "\n",
    "local_penalization_acq = LocalPenalizationAcquisitionFunction(search_space, num_samples=2000)\n",
    "local_penalization_acq_rule = EfficientGlobalOptimization(\n",
    "    num_query_points=2, builder=local_penalization_acq)\n",
    "points_chosen = local_penalization_acq_rule.acquire_single(search_space, initial_data, model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "points_chosen"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.]])>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "objective(points_chosen.numpy())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([10.96088904]), array([10.96088904])]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Doing observations in separate processes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from multiprocessing import Process, Manager\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "num_workers = 2\n",
    "num_observations = 10\n",
    "dataset = initial_data\n",
    "\n",
    "model_spec = build_model(initial_data)\n",
    "model = create_model(model_spec)\n",
    "\n",
    "model.optimize(initial_data)\n",
    "\n",
    "local_penalization_acq = LocalPenalizationAcquisitionFunction(search_space)\n",
    "local_penalization_acq_rule = EfficientGlobalOptimization(\n",
    "    num_query_points=2, builder=local_penalization_acq)\n",
    "\n",
    "m = Manager()\n",
    "pq = m.Queue()\n",
    "oq = m.Queue()\n",
    "\n",
    "def observer_proc(points_queue, observations_queue, cpu_id):\n",
    "    pid = os.getpid()\n",
    "    \n",
    "    current_process = psutil.Process()\n",
    "    current_process.cpu_affinity([cpu_id])\n",
    "    print(f\"Process {pid}: set CPU to {cpu_id}\", flush=True)\n",
    "    \n",
    "    while True:\n",
    "        point_to_observe = points_queue.get()\n",
    "        if (point_to_observe is None):\n",
    "            return\n",
    "        \n",
    "        print(f\"Process {pid}: observing data at point {point_to_observe}\", flush=True)\n",
    "        \n",
    "        # insert some artificial delay\n",
    "        # increases linearly with the absolute value of points\n",
    "        # which means our evaluations will take different time, good for exploring async\n",
    "        delay = 10 * np.sum(point_to_observe)\n",
    "        print(f\"Observer Process {pid} pretends like it's doing something for {delay:.2}s\", flush=True)\n",
    "        time.sleep(delay)\n",
    "        new_observation = objective(point_to_observe)\n",
    "        new_data = (point_to_observe, new_observation)\n",
    "        \n",
    "        print(f\"Observer Process {pid}: observed data {new_data}\", flush=True)\n",
    "        \n",
    "        observations_queue.put(new_data)\n",
    "\n",
    "\n",
    "observer_processes = []\n",
    "\n",
    "start = timeit.default_timer()\n",
    "try:\n",
    "    for i in range(psutil.cpu_count())[:num_workers]:\n",
    "        observer_p = Process(target=observer_proc, args=(pq, oq, i))\n",
    "        observer_p.daemon = True\n",
    "        observer_p.start()\n",
    "\n",
    "        observer_processes.append(observer_p)\n",
    "\n",
    "    # init the queue with first batch of points\n",
    "    points_chosen = local_penalization_acq_rule.acquire_single(search_space, initial_data, model)\n",
    "    for point in points_chosen:\n",
    "        pq.put(np.atleast_2d(point.numpy()))\n",
    "\n",
    "    pending_points = points_chosen\n",
    "\n",
    "    while len(dataset) < len(initial_data) + num_observations:\n",
    "        pid = os.getpid()\n",
    "        \n",
    "        try:\n",
    "            new_data = oq.get_nowait()\n",
    "            print(f\"Main Process {pid}: received data {new_data}\", flush=True)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        query_points = tf.constant(new_data[0], dtype=tf.float64)\n",
    "\n",
    "        # generate a tensor that contains True value for rows that equal to query_point\n",
    "        # False otherwise\n",
    "        # then use it to delete rows from pending points\n",
    "        mask = tf.reduce_any(tf.not_equal(pending_points, query_points), axis=1)\n",
    "        pending_points = tf.boolean_mask(pending_points, mask)\n",
    "\n",
    "        new_data = Dataset(query_points=query_points,\n",
    "                           observations=tf.constant(new_data[1], dtype=tf.float64),\n",
    "                          )\n",
    "        dataset = dataset + new_data\n",
    "\n",
    "        model.update(dataset)\n",
    "        model.optimize(dataset)\n",
    "\n",
    "        new_points = local_penalization_acq_rule.acquire_single(search_space, dataset, model, pending_points=pending_points)\n",
    "        pending_points = tf.concat([pending_points, new_points], axis=0)\n",
    "        new_points = new_points.numpy()\n",
    "        print(f\"Main Process {pid}: acquired point {new_points}\", flush=True)\n",
    "        for point in new_points:\n",
    "            pq.put(np.atleast_2d(point))\n",
    "finally:\n",
    "    for prc in observer_processes:\n",
    "        prc.terminate()\n",
    "        prc.join()\n",
    "        prc.close()\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(f\"Time : {stop - start}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Process 24965: set CPU to 0\n",
      "Process 24970: set CPU to 1\n",
      "Process 24965: observing data at point [[1. 0.]]Process 24970: observing data at point [[0. 1.]]\n",
      "Observer Process 24965 pretends like it's doing something for 1e+01s\n",
      "Observer Process 24970 pretends like it's doing something for 1e+01s\n",
      "\n",
      "Observer Process 24970: observed data (array([[0., 1.]]), [array([17.50829952])])Observer Process 24965: observed data (array([[1., 0.]]), [array([10.96088904])])\n",
      "Main Process 24474: received data (array([[1., 0.]]), [array([10.96088904])])\n",
      "\n",
      "Main Process 24474: acquired point [[0.2697947  0.99494766]\n",
      " [0.2388514  0.9991139 ]]\n",
      "Process 24965: observing data at point [[0.2697947  0.99494766]]Process 24970: observing data at point [[0.2388514 0.9991139]]Main Process 24474: received data (array([[0., 1.]]), [array([17.50829952])])\n",
      "\n",
      "Observer Process 24970 pretends like it's doing something for 1.2e+01s\n",
      "Observer Process 24965 pretends like it's doing something for 1.3e+01s\n",
      "\n",
      "Main Process 24474: acquired point [[1.         0.24806013]\n",
      " [1.         0.24806013]]\n",
      "Observer Process 24970: observed data (array([[0.2388514, 0.9991139]]), [array([53.35099047])])\n",
      "Process 24970: observing data at point [[1.         0.24806013]]Main Process 24474: received data (array([[0.2388514, 0.9991139]]), [array([53.35099047])])\n",
      "\n",
      "Observer Process 24970 pretends like it's doing something for 1.2e+01s\n",
      "Observer Process 24965: observed data (array([[0.2697947 , 0.99494766]]), [array([68.7053417])])\n",
      "Process 24965: observing data at point [[1.         0.24806013]]\n",
      "Observer Process 24965 pretends like it's doing something for 1.2e+01s\n",
      "Main Process 24474: acquired point [[1.         0.12046064]\n",
      " [1.         0.12046063]]\n",
      "Main Process 24474: received data (array([[0.2697947 , 0.99494766]]), [array([68.7053417])])\n",
      "Main Process 24474: acquired point [[0.65416767 0.        ]\n",
      " [0.65416767 0.        ]]\n",
      "Observer Process 24970: observed data (array([[1.        , 0.24806013]]), [array([2.45858615])])\n",
      "Process 24970: observing data at point [[1.         0.12046064]]Main Process 24474: received data (array([[1.        , 0.24806013]]), [array([2.45858615])])\n",
      "\n",
      "Observer Process 24970 pretends like it's doing something for 1.1e+01s\n",
      "Observer Process 24965: observed data (array([[1.        , 0.24806013]]), [array([2.45858619])])\n",
      "Process 24965: observing data at point [[1.         0.12046063]]\n",
      "Observer Process 24965 pretends like it's doing something for 1.1e+01s\n",
      "Main Process 24474: acquired point [[0.72081075 0.27783745]\n",
      " [0.72081077 0.27783746]]\n",
      "Main Process 24474: received data (array([[1.        , 0.24806013]]), [array([2.45858619])])\n",
      "Main Process 24474: acquired point [[0.04202388 0.66094961]\n",
      " [0.04202389 0.66094962]]\n",
      "Observer Process 24970: observed data (array([[1.        , 0.12046064]]), [array([3.37366913])])\n",
      "Main Process 24474: received data (array([[1.        , 0.12046064]]), [array([3.37366913])])\n",
      "Process 24970: observing data at point [[0.65416767 0.        ]]\n",
      "Observer Process 24970 pretends like it's doing something for 6.5s\n",
      "Observer Process 24965: observed data (array([[1.        , 0.12046063]]), [array([3.37366945])])\n",
      "Process 24965: observing data at point [[0.65416767 0.        ]]\n",
      "Observer Process 24965 pretends like it's doing something for 6.5s\n",
      "Main Process 24474: acquired point [[0.53800131 0.27094851]\n",
      " [0.54752484 0.24422512]]\n",
      "Main Process 24474: received data (array([[1.        , 0.12046063]]), [array([3.37366945])])\n",
      "Main Process 24474: acquired point [[0.8639056  0.17442392]\n",
      " [0.86621853 0.15958127]]\n",
      "Observer Process 24970: observed data (array([[0.65416767, 0.        ]]), [array([12.73562962])])\n",
      "Main Process 24474: received data (array([[0.65416767, 0.        ]]), [array([12.73562962])])\n",
      "Process 24970: observing data at point [[0.72081075 0.27783745]]\n",
      "Observer Process 24970 pretends like it's doing something for 1e+01s\n",
      "Observer Process 24965: observed data (array([[0.65416767, 0.        ]]), [array([12.73562974])])\n",
      "Process 24965: observing data at point [[0.72081077 0.27783746]]\n",
      "Observer Process 24965 pretends like it's doing something for 1e+01s\n",
      "Main Process 24474: acquired point [[0.83766032 0.27731685]\n",
      " [0.83396049 0.25696275]]\n",
      "Main Process 24474: received data (array([[0.65416767, 0.        ]]), [array([12.73562974])])\n",
      "Main Process 24474: acquired point [[0.76773434 0.15132146]\n",
      " [0.76773434 0.15132144]]\n",
      "Time : 57.96770138099964\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset(query_points=<tf.Tensor: shape=(13, 2), dtype=float64, numpy=\n",
       "array([[0.05866792, 0.08743693],\n",
       "       [0.65182824, 0.57646759],\n",
       "       [0.97908318, 0.87241814],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.2388514 , 0.9991139 ],\n",
       "       [0.2697947 , 0.99494766],\n",
       "       [1.        , 0.24806013],\n",
       "       [1.        , 0.24806013],\n",
       "       [1.        , 0.12046064],\n",
       "       [1.        , 0.12046063],\n",
       "       [0.65416767, 0.        ],\n",
       "       [0.65416767, 0.        ]])>, observations=<tf.Tensor: shape=(13, 1), dtype=float64, numpy=\n",
       "array([[185.22940936],\n",
       "       [ 63.94383844],\n",
       "       [108.50778776],\n",
       "       [ 10.96088904],\n",
       "       [ 17.50829952],\n",
       "       [ 53.35099047],\n",
       "       [ 68.7053417 ],\n",
       "       [  2.45858615],\n",
       "       [  2.45858619],\n",
       "       [  3.37366913],\n",
       "       [  3.37366945],\n",
       "       [ 12.73562962],\n",
       "       [ 12.73562974]])>)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "interpreter": {
   "hash": "2e5482bfae22a9860093954525ec1034719f5a38058d080fab0a84657e9e30ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}