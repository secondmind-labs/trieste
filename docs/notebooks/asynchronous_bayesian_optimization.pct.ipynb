{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be49f89f",
   "metadata": {},
   "source": [
    "# Asynchronous Bayesian optimization with Trieste\n",
    "\n",
    "In this notebook we show how Bayesian optimization can be done asynchronuosly. That is pertinent in scenarios when the objective function we are aiming to optimize can be run for several points in parallel, and observations might return back at different times. To avoid wasting resources we immediatelly request the next point asynchronuosly, taking into account points that still being evaluated.\n",
    "\n",
    "To contrast this approach with regular [batch optimization](batch_optimization.ipynb), this notebook also shows how to run parallel synchronous batch approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2922d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence TF warnings and info messages, only print errors\n",
    "# https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b3e54",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "First, let's define a simple objective that will emulate workload of variable time. We will be using class BO benchmark function [Branin](https://www.sfu.ca/~ssurjano/branin.html), and insert sleep call in the middle of the calculation to emulate delay. Our sleep delay is a scaled sum of all input values to make sure delays are uneven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a09715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42052567]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(points, sleep=True):\n",
    "    if points.shape[1] != 2:\n",
    "        raise ValueError(f\"Incorrect input shape, expected (*, 2), got {points.shape}\")\n",
    "\n",
    "    def scaled_branin(x):\n",
    "        x0 = x[..., :1] * 15.0 - 5.0\n",
    "        x1 = x[..., 1:] * 15.0\n",
    "\n",
    "        b = 5.1 / (4 * math.pi ** 2)\n",
    "        c = 5 / math.pi\n",
    "        r = 6\n",
    "        s = 10\n",
    "        t = 1 / (8 * math.pi)\n",
    "        scale = 1 / 51.95\n",
    "        translate = -44.81\n",
    "\n",
    "        if sleep:\n",
    "            # insert some artificial delay\n",
    "            # increases linearly with the absolute value of points\n",
    "            # which means our evaluations will take different time\n",
    "            delay = 5 * np.sum(x)\n",
    "            pid = os.getpid()\n",
    "            print(\n",
    "                f\"Process {pid}: Objective: pretends like it's doing something for {delay:.2}s\",\n",
    "                flush=True,\n",
    "            )\n",
    "            time.sleep(delay)\n",
    "\n",
    "        return scale * ((x1 - b * x0 ** 2 + c * x0 - r) ** 2 + s * (1 - t) * np.cos(x0) + translate)\n",
    "\n",
    "    observations = []\n",
    "    for point in points:\n",
    "        observation = scaled_branin(point)\n",
    "        observations.append(observation)\n",
    "\n",
    "    return np.array(observations)\n",
    "\n",
    "# test the defined objective function\n",
    "objective(np.array([[0.1, 0.5]]), sleep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc47225",
   "metadata": {},
   "source": [
    "As always, we need to prepare model and some initial data to kick-start the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9640852d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from trieste.space import Box\n",
    "from trieste.data import Dataset\n",
    "from trieste.objectives import SCALED_BRANIN_MINIMUM\n",
    "\n",
    "search_space = Box([0, 0], [1, 1])\n",
    "num_initial_points = 3\n",
    "initial_query_points = search_space.sample(num_initial_points)\n",
    "initial_observations = objective(initial_query_points.numpy(), sleep=False)\n",
    "initial_data = Dataset(\n",
    "    query_points=initial_query_points,\n",
    "    observations=tf.constant(initial_observations, dtype=tf.float64),\n",
    ")\n",
    "\n",
    "import gpflow\n",
    "from trieste.models import create_model\n",
    "from trieste.models.gpflow.config import GPflowModelConfig\n",
    "\n",
    "\n",
    "def build_model(data):\n",
    "    variance = tf.math.reduce_variance(data.observations)\n",
    "    kernel = gpflow.kernels.RBF(variance=variance)\n",
    "    gpr = gpflow.models.GPR(data.astuple(), kernel, noise_variance=1e-5)\n",
    "    gpflow.set_trainable(gpr.likelihood, False)\n",
    "\n",
    "    return GPflowModelConfig(\n",
    "        **{\n",
    "            \"model\": gpr,\n",
    "            \"optimizer\": gpflow.optimizers.Scipy(),\n",
    "            \"optimizer_args\": {\n",
    "                \"minimize_args\": {\"options\": dict(maxiter=100)},\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "# these imports will be used later for optimization\n",
    "from trieste.acquisition import LocalPenalizationAcquisitionFunction\n",
    "from trieste.acquisition.rule import AsyncEfficientGlobalOptimization, EfficientGlobalOptimization\n",
    "from trieste.ask_tell_optimization import AskTellOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed9cf3",
   "metadata": {},
   "source": [
    "## Multiprocessing setup\n",
    "\n",
    "To keep this notebook as reproducible as possible, we will only be using Python's multiprocessing package here. In this section we will explain our setup and define some common code to be used later.\n",
    "\n",
    "In both synchronous and asynchronous scenarios we will have a fixed set of worker processes performing observations. We will also have a main process responsible for optimization process with Trieste. When Trieste suggests a new point, it is inserted into a points queue. One of the workers picks this point from the queue, performs the observation, and inserts the output into observations queue. The main process then picks up the observation from the queue, at which moment it either waits for the rest of the points in the batch to come back (synchronous scenario) or immediately suggests a new point (asynchrunous scenario). This process continues either for a certain number of iterations or until we accumulate necessary number of observations.\n",
    "\n",
    "The overall setup is illustrated in this diagram:\n",
    "![multiprocessing setup](figures/async_bo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf9b409",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Necessary multiprocessing primitives\n",
    "from multiprocessing import Manager, Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f26439",
   "metadata": {},
   "source": [
    "We now define several common functions to implement the described setup. First we define a worker function that will be running a single observation in a separate process. Worker takes both queues as an input, reads next point from the points queue, makes an observation, and inserts observed data into the observations queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54048ff9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def observer_proc(points_queue, observations_queue):\n",
    "    pid = os.getpid()\n",
    "\n",
    "    while True:\n",
    "        point_to_observe = points_queue.get()\n",
    "        if point_to_observe is None:\n",
    "            return\n",
    "\n",
    "        print(f\"Process {pid}: Observer : observing data at point {point_to_observe}\", flush=True)\n",
    "        new_observation = objective(point_to_observe, sleep=enable_sleep_delays)\n",
    "        new_data = (point_to_observe, new_observation)\n",
    "\n",
    "        print(f\"Process {pid}: Observer : observed data {new_data}\", flush=True)\n",
    "\n",
    "        observations_queue.put(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e3c2de",
   "metadata": {},
   "source": [
    "Next we define two helper functions, one is to create a certain number of worker processes, and another is to terminate them once we are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ae8838",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_worker_processes(n_workers, points_queue, obseverations_queue):\n",
    "    observer_processes = []\n",
    "    for i in range(n_workers):\n",
    "        worker_proc = Process(target=observer_proc, args=(points_queue, obseverations_queue))\n",
    "        worker_proc.daemon = True\n",
    "        worker_proc.start()\n",
    "\n",
    "        observer_processes.append(worker_proc)\n",
    "\n",
    "    return observer_processes\n",
    "\n",
    "def terminate_processes(processes):\n",
    "    for prc in processes:\n",
    "        prc.terminate()\n",
    "        prc.join()\n",
    "        prc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829817eb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Finally we set some common parameters. See comments below for explanation of what each one means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf5ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of worker processes to run simultaneously\n",
    "# Setting this to 1 will turn both setups into non-batch sequential optimization\n",
    "num_workers = 3\n",
    "# Number of iterations to run the sycnhronous scenario for\n",
    "num_iterations = 10\n",
    "# Number of observations to collect in asynchronous scenario\n",
    "num_observations = num_workers * num_iterations\n",
    "# Set this flag to False to disable sleep delays in case you want the notebook to execute quickly\n",
    "enable_sleep_delays = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd97a865",
   "metadata": {},
   "source": [
    "## Asynchronous optimization\n",
    "This section runs the asynchronous optimization routine. We first setup the [ask/tell optimizer](ask_tell_optimization.ipynb). Notice that we use **AsyncEfficientGlobalOptimization** rule specifically designed for asynchronous scenarios. Next we create thread-safe queues for points and observations, and run the optimization loop.\n",
    "\n",
    "Crucially, even though we are using batch acquisition function Local Penalization, we specify batch size of 1. This is because we don't really want a batch. Since the amout of workers we have is fixed, whenever we see a new observation we only need one point back. However this process can only be done with acquisition funcitons that implement greedy batch collection strategies, because they are able to take into account points that are currently being observed (in Trieste we call them \"pending\"). Trieste currently provides two such functions: Local Penalization and GIBBON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e89b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 581: Observer : observing data at point [[0.22017248 0.41410065]]\n",
      "\n",
      "Process 581: Objective: pretends like it's doing something for 3.2sProcess 585: Observer : observing data at point [[0.42175627 0.40709014]]\n",
      "Process 585: Objective: pretends like it's doing something for 4.1s\n",
      "Process 589: Observer : observing data at point [[0.18505324 0.53458144]]\n",
      "Process 589: Objective: pretends like it's doing something for 3.6s\n",
      "Process 581: Observer : observed data (array([[0.22017248, 0.41410065]]), array([[-0.72820537]]))\n",
      "Process 32404: Main     : received data (array([[0.22017248, 0.41410065]]), array([[-0.72820537]]))\n",
      "Process 32404: Main     : acquired point [[0.30556602 0.25428518]]\n",
      "Process 581: Observer : observing data at point [[0.30556602 0.25428518]]\n",
      "Process 581: Objective: pretends like it's doing something for 2.8s\n",
      "Process 589: Observer : observed data (array([[0.18505324, 0.53458144]]), array([[-0.88508586]]))\n",
      "Process 32404: Main     : received data (array([[0.18505324, 0.53458144]]), array([[-0.88508586]]))\n",
      "Process 585: Observer : observed data (array([[0.42175627, 0.40709014]]), array([[-0.7415941]]))\n",
      "Process 32404: Main     : acquired point [[0.05060607 0.54213271]]\n",
      "Process 589: Observer : observing data at point [[0.05060607 0.54213271]]\n",
      "Process 32404: Main     : received data (array([[0.42175627, 0.40709014]]), array([[-0.7415941]]))\n",
      "Process 589: Objective: pretends like it's doing something for 3.0s\n",
      "Process 32404: Main     : acquired point [[0.03970399 0.62129399]]\n",
      "Process 585: Observer : observing data at point [[0.03970399 0.62129399]]\n",
      "Process 585: Objective: pretends like it's doing something for 3.3s\n",
      "Process 581: Observer : observed data (array([[0.30556602, 0.25428518]]), array([[-0.53486037]]))\n",
      "Process 32404: Main     : received data (array([[0.30556602, 0.25428518]]), array([[-0.53486037]]))\n",
      "Process 32404: Main     : acquired point [[0.         0.50995193]]\n",
      "Process 581: Observer : observing data at point [[0.         0.50995193]]\n",
      "Process 581: Objective: pretends like it's doing something for 2.5s\n",
      "Process 589: Observer : observed data (array([[0.05060607, 0.54213271]]), array([[-0.01911784]]))\n",
      "Process 32404: Main     : received data (array([[0.05060607, 0.54213271]]), array([[-0.01911784]]))\n",
      "Process 32404: Main     : acquired point [[0.21901177 0.52396713]]\n",
      "Process 589: Observer : observing data at point [[0.21901177 0.52396713]]\n",
      "Process 589: Objective: pretends like it's doing something for 3.7s\n",
      "Process 585: Observer : observed data (array([[0.03970399, 0.62129399]]), array([[-0.17946834]]))\n",
      "Process 32404: Main     : received data (array([[0.03970399, 0.62129399]]), array([[-0.17946834]]))\n",
      "Process 581: Observer : observed data (array([[0.        , 0.50995193]]), array([[0.94107304]]))\n",
      "Process 32404: Main     : acquired point [[0.21361299 0.59354547]]\n",
      "Process 32404: Main     : received data (array([[0.        , 0.50995193]]), array([[0.94107304]]))\n",
      "Process 585: Observer : observing data at point [[0.21361299 0.59354547]]\n",
      "Process 585: Objective: pretends like it's doing something for 4.0s\n",
      "Process 32404: Main     : acquired point [[0.33559135 0.36868176]]\n",
      "Process 581: Observer : observing data at point [[0.33559135 0.36868176]]\n",
      "Process 581: Objective: pretends like it's doing something for 3.5s\n",
      "Process 589: Observer : observed data (array([[0.21901177, 0.52396713]]), array([[-0.85903145]]))\n",
      "Process 32404: Main     : received data (array([[0.21901177, 0.52396713]]), array([[-0.85903145]]))\n",
      "Process 32404: Main     : acquired point [[0.4669706  0.28475088]]\n",
      "Process 589: Observer : observing data at point [[0.4669706  0.28475088]]\n",
      "Process 589: Objective: pretends like it's doing something for 3.8s\n",
      "Process 585: Observer : observed data (array([[0.21361299, 0.59354547]]), array([[-0.90114213]]))\n",
      "Process 32404: Main     : received data (array([[0.21361299, 0.59354547]]), array([[-0.90114213]]))\n",
      "Process 581: Observer : observed data (array([[0.33559135, 0.36868176]]), array([[-0.67450097]]))\n",
      "Process 32404: Main     : acquired point [[0.86845254 0.        ]]\n",
      "Process 32404: Main     : received data (array([[0.33559135, 0.36868176]]), array([[-0.67450097]]))\n",
      "Process 585: Observer : observing data at point [[0.86845254 0.        ]]\n",
      "Process 585: Objective: pretends like it's doing something for 4.3s\n",
      "Process 32404: Main     : acquired point [[1. 1.]]\n",
      "Process 581: Observer : observing data at point [[1. 1.]]\n",
      "Process 581: Objective: pretends like it's doing something for 1e+01s\n",
      "Process 589: Observer : observed data (array([[0.4669706 , 0.28475088]]), array([[-0.92314352]]))\n",
      "Process 32404: Main     : received data (array([[0.4669706 , 0.28475088]]), array([[-0.92314352]]))\n",
      "Process 32404: Main     : acquired point [[0.68578979 0.        ]]\n",
      "Process 589: Observer : observing data at point [[0.68578979 0.        ]]\n",
      "Process 589: Objective: pretends like it's doing something for 3.4s\n",
      "Process 585: Observer : observed data (array([[0.86845254, 0.        ]]), array([[-0.84820041]]))\n",
      "Process 32404: Main     : received data (array([[0.86845254, 0.        ]]), array([[-0.84820041]]))\n",
      "Process 32404: Main     : acquired point [[0.67526797 0.15159771]]\n",
      "Process 585: Observer : observing data at point [[0.67526797 0.15159771]]\n",
      "Process 585: Objective: pretends like it's doing something for 4.1s\n",
      "Process 589: Observer : observed data (array([[0.68578979, 0.        ]]), array([[-0.73456654]]))\n",
      "Process 32404: Main     : received data (array([[0.68578979, 0.        ]]), array([[-0.73456654]]))\n",
      "Process 32404: Main     : acquired point [[0.67642413 0.21856934]]\n",
      "Process 589: Observer : observing data at point [[0.67642413 0.21856934]]\n",
      "Process 589: Objective: pretends like it's doing something for 4.5s\n",
      "Process 585: Observer : observed data (array([[0.67526797, 0.15159771]]), array([[-0.76699665]]))\n",
      "Process 32404: Main     : received data (array([[0.67526797, 0.15159771]]), array([[-0.76699665]]))\n",
      "Process 32404: Main     : acquired point [[0.80573592 1.        ]]\n",
      "Process 585: Observer : observing data at point [[0.80573592 1.        ]]\n",
      "Process 585: Objective: pretends like it's doing something for 9.0s\n",
      "Process 581: Observer : observed data (array([[1., 1.]]), array([[1.75288144]]))\n",
      "Process 32404: Main     : received data (array([[1., 1.]]), array([[1.75288144]]))\n",
      "Process 32404: Main     : acquired point [[1. 0.]]\n",
      "Process 581: Observer : observing data at point [[1. 0.]]\n",
      "Process 581: Objective: pretends like it's doing something for 5.0s\n",
      "Process 589: Observer : observed data (array([[0.67642413, 0.21856934]]), array([[-0.7041221]]))Process 32404: Main     : received data (array([[0.67642413, 0.21856934]]), array([[-0.7041221]]))\n",
      "\n",
      "Process 32404: Main     : acquired point [[1.         0.05323119]]\n",
      "Process 589: Observer : observing data at point [[1.         0.05323119]]\n",
      "Process 589: Objective: pretends like it's doing something for 5.3s\n",
      "Process 581: Observer : observed data (array([[1., 0.]]), array([[-0.84406373]]))\n",
      "Process 32404: Main     : received data (array([[1., 0.]]), array([[-0.84406373]]))\n",
      "Process 32404: Main     : acquired point [[0.00792942 1.        ]]\n",
      "Process 581: Observer : observing data at point [[0.00792942 1.        ]]\n",
      "\n",
      "Process 581: Objective: pretends like it's doing something for 5.0sProcess 589: Observer : observed data (array([[1.        , 0.05323119]]), array([[-0.9241018]]))\n",
      "Process 32404: Main     : received data (array([[1.        , 0.05323119]]), array([[-0.9241018]]))\n",
      "Process 32404: Main     : acquired point [[1.         0.29233876]]\n",
      "Process 589: Observer : observing data at point [[1.         0.29233876]]\n",
      "Process 589: Objective: pretends like it's doing something for 6.5s\n",
      "Process 585: Observer : observed data (array([[0.80573592, 1.        ]]), array([[2.92698159]]))\n",
      "Process 32404: Main     : received data (array([[0.80573592, 1.        ]]), array([[2.92698159]]))\n",
      "Process 32404: Main     : acquired point [[0.12075451 1.        ]]\n",
      "Process 585: Observer : observing data at point [[0.12075451 1.        ]]\n",
      "Process 585: Objective: pretends like it's doing something for 5.6s\n",
      "Process 581: Observer : observed data (array([[0.00792942, 1.        ]]), array([[-0.76591927]]))\n",
      "Process 32404: Main     : received data (array([[0.00792942, 1.        ]]), array([[-0.76591927]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 32404: Main     : acquired point [[0.11388418 0.84610943]]\n",
      "Process 581: Observer : observing data at point [[0.11388418 0.84610943]]\n",
      "Process 581: Objective: pretends like it's doing something for 4.8s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup Ask Tell BO\n",
    "model_spec = build_model(initial_data)\n",
    "model = create_model(model_spec)\n",
    "\n",
    "local_penalization_acq = LocalPenalizationAcquisitionFunction(search_space, num_samples=2000)\n",
    "local_penalization_rule = AsyncEfficientGlobalOptimization(num_query_points=1, builder=local_penalization_acq)  # type: ignore\n",
    "\n",
    "async_bo = AskTellOptimizer(search_space, initial_data, model, local_penalization_rule)\n",
    "\n",
    "# retrieve process id for nice logging\n",
    "pid = os.getpid()\n",
    "# create point and observation queues\n",
    "m = Manager()\n",
    "pq = m.Queue()\n",
    "oq = m.Queue()\n",
    "# keep track of all workers we have launched\n",
    "observer_processes = []\n",
    "# counter to keep track of collected observations\n",
    "points_observed = 0\n",
    "\n",
    "start = timeit.default_timer()\n",
    "try:\n",
    "    observer_processes = create_worker_processes(num_workers, pq, oq)\n",
    "\n",
    "    # init the queue with first batch of points\n",
    "    for _ in range(num_workers):\n",
    "        point = async_bo.ask()\n",
    "        pq.put(np.atleast_2d(point.numpy()))\n",
    "\n",
    "    while points_observed < num_observations:\n",
    "        # keep asking queue for new observations until one arrives\n",
    "        try:\n",
    "            new_data = oq.get_nowait()\n",
    "            print(f\"Process {pid}: Main     : received data {new_data}\", flush=True)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # new_data is a tuple of (point, observation value)\n",
    "        # here we turn it into a Dataset and tell of it Trieste\n",
    "        points_observed += 1\n",
    "        new_data = Dataset(\n",
    "            query_points=tf.constant(new_data[0], dtype=tf.float64),\n",
    "            observations=tf.constant(new_data[1], dtype=tf.float64),\n",
    "        )\n",
    "        async_bo.tell(new_data)\n",
    "\n",
    "        # now we can ask Trieste for one more point\n",
    "        # and feed that back into the points queue\n",
    "        point = async_bo.ask()\n",
    "        print(f\"Process {pid}: Main     : acquired point {point}\", flush=True)\n",
    "        pq.put(np.atleast_2d(point))\n",
    "finally:\n",
    "    terminate_processes(observer_processes)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "# Collect the observations, compute the running time\n",
    "async_lp_observations = async_bo.to_result().try_get_final_dataset().observations - SCALED_BRANIN_MINIMUM\n",
    "async_lp_time = stop - start\n",
    "print(f\"Got {len(async_lp_observations)} in {async_lp_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfa0e7",
   "metadata": {},
   "source": [
    "## Synchronous parallel optimization\n",
    "\n",
    "This section runs the synchronous parallel optimization with Trieste. We again use Local Penalization acquisition function, but this time with batch size equal to the number of workers we have available. Once Trieste suggests the batch, we add all points to the point queue, and workers immediatelly pick them up, one point per worker. Therefore all points in the batch are evaluated in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87baf734",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# setup Ask Tell BO\n",
    "model_spec = build_model(initial_data)\n",
    "model = create_model(model_spec)\n",
    "\n",
    "local_penalization_acq = LocalPenalizationAcquisitionFunction(search_space, num_samples=2000)\n",
    "local_penalization_rule = EfficientGlobalOptimization(  # type: ignore\n",
    "    num_query_points=num_workers, builder=local_penalization_acq\n",
    ")\n",
    "\n",
    "sync_bo = AskTellOptimizer(search_space, initial_data, model, local_penalization_rule)\n",
    "\n",
    "\n",
    "# retrieve process id for nice logging\n",
    "pid = os.getpid()\n",
    "# create point and observation queues\n",
    "m = Manager()\n",
    "pq = m.Queue()\n",
    "oq = m.Queue()\n",
    "# keep track of all workers we have launched\n",
    "observer_processes = []\n",
    "\n",
    "start = timeit.default_timer()\n",
    "try:\n",
    "    observer_processes = create_worker_processes(num_workers, pq, oq)\n",
    "\n",
    "    # BO loop starts here\n",
    "    for i in range(num_iterations):\n",
    "        print(f\"Process {pid}: Main     : iteration {i} starts\", flush=True)\n",
    "\n",
    "        # get a batch of points from Trieste, send them to points queue\n",
    "        # each worker picks up a point and processes it\n",
    "        points = sync_bo.ask()\n",
    "        for point in points.numpy():\n",
    "            pq.put(point.reshape(1, -1))  # reshape is to make point a 2d array\n",
    "\n",
    "        # now we wait for all workers to finish\n",
    "        # we create an empty dataset and wait\n",
    "        # until we collected as many observations in it\n",
    "        # as there were points in the batch\n",
    "        all_new_data = Dataset(\n",
    "            tf.zeros((0, initial_data.query_points.shape[1]), tf.float64),\n",
    "            tf.zeros((0, initial_data.observations.shape[1]), tf.float64),\n",
    "        )\n",
    "        while len(all_new_data) < num_workers:\n",
    "            # this line blocks the process until new data is available in the queue\n",
    "            new_data = oq.get()\n",
    "            print(f\"Process {pid}: Main     : received data {new_data}\", flush=True)\n",
    "\n",
    "            new_data = Dataset(\n",
    "                query_points=tf.constant(new_data[0], dtype=tf.float64),\n",
    "                observations=tf.constant(new_data[1], dtype=tf.float64),\n",
    "            )\n",
    "\n",
    "            all_new_data = all_new_data + new_data\n",
    "\n",
    "        # tell Trieste of new batch of observations\n",
    "        sync_bo.tell(all_new_data)\n",
    "\n",
    "finally:\n",
    "    terminate_processes(observer_processes)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "# Collect the observations, compute the running time\n",
    "sync_lp_observations = (\n",
    "    sync_bo.to_result().try_get_final_dataset().observations - SCALED_BRANIN_MINIMUM\n",
    ")\n",
    "sync_lp_time = stop - start\n",
    "print(f\"Got {len(sync_lp_observations)} in {sync_lp_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef97e1",
   "metadata": {},
   "source": [
    "To compare outcomes of sync and async runs, let's plot their respective regrets side by side, and print out the running time. We expect async scenario to run a little bit faster for this toy problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trieste.objectives import SCALED_BRANIN_MINIMUM\n",
    "\n",
    "from util.plotting import plot_regret\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "sync_lp_min_idx = tf.squeeze(tf.argmin(sync_lp_observations, axis=0))\n",
    "async_lp_min_idx = tf.squeeze(tf.argmin(async_lp_observations, axis=0))\n",
    "\n",
    "plot_regret(\n",
    "    sync_lp_observations.numpy(), ax[0], num_init=len(initial_data), idx_best=sync_lp_min_idx\n",
    ")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_ylabel(\"Regret\")\n",
    "ax[0].set_ylim(0.0000001, 100)\n",
    "ax[0].set_xlabel(\"# evaluations\")\n",
    "ax[0].set_title(f\"Sync LP, {len(sync_lp_observations)} points, time {sync_lp_time:.2f}\")\n",
    "\n",
    "plot_regret(\n",
    "    async_lp_observations.numpy(), ax[1], num_init=len(initial_data), idx_best=async_lp_min_idx\n",
    ")\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_ylabel(\"Regret\")\n",
    "ax[1].set_ylim(0.0000001, 100)\n",
    "ax[1].set_xlabel(\"# evaluations\")\n",
    "ax[1].set_title(f\"Async LP, {len(async_lp_observations)} points, time {async_lp_time:.2f}s\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc90828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
