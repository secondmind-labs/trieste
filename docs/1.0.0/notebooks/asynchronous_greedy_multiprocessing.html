
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Asynchronous Bayesian optimization with Trieste &#8212; trieste 1.0.0 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Asynchronous batch Bayesian optimization" href="asynchronous_nongreedy_batch_ray.html" />
    <link rel="prev" title="Recovering from errors during optimization" href="recovering_from_errors.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  Trieste
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../autoapi/trieste/index.html">
  API reference
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-primary btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        1.0.0  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables notebooks/asynchronous_greedy_multiprocessing and {'json_url': 'https://secondmind-labs.github.io/trieste/versions.json', 'version_match': '1.0.0'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "notebooks/asynchronous_greedy_multiprocessing.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://secondmind-labs.github.io/trieste/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "notebooks/asynchronous_greedy_multiprocessing.html";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "1.0.0") {
                node.classList.add("active");
                let btn = document.getElementById("version_switcher_button");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/secondmind-labs/trieste" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="expected_improvement.html">
   Noise-free optimization with Expected Improvement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="batch_optimization.html">
   Batch Bayesian Optimization with Batch Expected Improvement, Local Penalization, Kriging Believer and GIBBON
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="thompson_sampling.html">
   Batch-sequential optimization with Thompson sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="inequality_constraints.html">
   Inequality constraints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="explicit_constraints.html">
   Explicit Constraints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="failure_ego.html">
   EGO with a failure region
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multi_objective_ehvi.html">
   Multi-objective optimization with Expected HyperVolume Improvement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deep_gaussian_processes.html">
   Using deep Gaussian processes with GPflux for Bayesian optimization.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deep_ensembles.html">
   Bayesian optimization with deep ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="active_learning.html">
   Active Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="active_learning_for_binary_classification.html">
   Active Learning for Gaussian Process Classification Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feasible_sets.html">
   Bayesian active learning of failure or feasibility regions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openai_gym_lunar_lander.html">
   Trieste meets OpenAI Gym
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scalable_thompson_sampling_using_sparse_gaussian_processes.html">
   Scalable Thompson Sampling using Sparse Gaussian Process Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="qhsri-tutorial.html">
   Batch HSRI Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multifidelity_modelling.html">
   Multifidelity Modelling with Autoregressive Model
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ask_tell_optimization.html">
   Ask-Tell Optimization Interface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data_transformation.html">
   Data transformation with the help of Ask-Tell interface.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="recovering_from_errors.html">
   Recovering from errors during optimization
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Asynchronous Bayesian optimization with Trieste
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="asynchronous_nongreedy_batch_ray.html">
   Asynchronous batch Bayesian optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="visualizing_with_tensorboard.html">
   Tracking and visualizing optimizations using Tensorboard
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="code_overview.html">
   An overview of Trieste types
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Multiprocessing-setup">
   Multiprocessing setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Asynchronous-optimization">
   Asynchronous optimization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Synchronous-parallel-optimization">
   Synchronous parallel optimization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Comparison">
   Comparison
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Asynchronous-Bayesian-optimization-with-Trieste">
<h1>Asynchronous Bayesian optimization with Trieste<a class="headerlink" href="#Asynchronous-Bayesian-optimization-with-Trieste" title="Permalink to this headline">#</a></h1>
<p>In this notebook we demonstrate Trieste’s ability to perform asynchronous Bayesian optimisation, as is suitable for scenarios where the objective function can be run for several points in parallel but where observations might return back at different times. To avoid wasting resources waiting for the evaluation of the whole batch, we immediately request the next point asynchronously, taking into account points that are still being evaluated. Besides saving resources, asynchronous approach also
can potentially <a class="reference external" href="https://arxiv.org/abs/1901.10452">improve sample efficiency</a> in comparison with synchronous batch strategies, although this is highly dependent on the use case.</p>
<p>To contrast this approach with regular <a class="reference internal" href="batch_optimization.html"><span class="doc">batch optimization</span></a>, this notebook also shows how to run parallel synchronous batch approach.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># silence TF warnings and info messages, only print errors</span>
<span class="c1"># https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_CPP_MIN_LOG_LEVEL&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;3&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s2">&quot;ERROR&quot;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">timeit</span>
</pre></div>
</div>
</div>
<p>First, let’s define a simple objective that will emulate evaluations taking variable time. We will be using a classic Bayesian optimisation benchmark function <a class="reference external" href="https://www.sfu.ca/~ssurjano/branin.html">Branin</a> with a sleep call inserted in the middle of the calculation to emulate delay. Our sleep delay is a scaled sum of all input values to make sure delays are uneven.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">trieste.objectives</span> <span class="kn">import</span> <span class="n">ScaledBranin</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">sleep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Incorrect input shape, expected (*, 2), got </span><span class="si">{</span><span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">observations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">ScaledBranin</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sleep</span><span class="p">:</span>
            <span class="c1"># insert some artificial delay</span>
            <span class="c1"># increases linearly with the absolute value of points</span>
            <span class="c1"># which means our evaluations will take different time</span>
            <span class="n">delay</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
            <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">: Objective: pretends like it&#39;s doing something for </span><span class="si">{</span><span class="n">delay</span><span class="si">:</span><span class="s2">.2</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">,</span>
                <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">delay</span><span class="p">)</span>
        <span class="n">observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>


<span class="c1"># test the defined objective function</span>
<span class="n">objective</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]),</span> <span class="n">sleep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[-0.42052567]])
</pre></div></div>
</div>
<p>As always, we need to prepare the model and some initial data to kick-start the optimization process.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">trieste.space</span> <span class="kn">import</span> <span class="n">Box</span>
<span class="kn">from</span> <span class="nn">trieste.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">search_space</span> <span class="o">=</span> <span class="n">Box</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">num_initial_points</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">initial_query_points</span> <span class="o">=</span> <span class="n">search_space</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_initial_points</span><span class="p">)</span>
<span class="n">initial_observations</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">initial_query_points</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">sleep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">initial_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
    <span class="n">query_points</span><span class="o">=</span><span class="n">initial_query_points</span><span class="p">,</span>
    <span class="n">observations</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">initial_observations</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">gpflow</span>
<span class="kn">from</span> <span class="nn">trieste.models.gpflow</span> <span class="kn">import</span> <span class="n">GaussianProcessRegression</span><span class="p">,</span> <span class="n">build_gpr</span>

<span class="c1"># We set the likelihood variance to a small number because</span>
<span class="c1"># we are dealing with a noise-free problem.</span>
<span class="n">gpflow_model</span> <span class="o">=</span> <span class="n">build_gpr</span><span class="p">(</span><span class="n">initial_data</span><span class="p">,</span> <span class="n">search_space</span><span class="p">,</span> <span class="n">likelihood_variance</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianProcessRegression</span><span class="p">(</span><span class="n">gpflow_model</span><span class="p">)</span>


<span class="c1"># these imports will be used later for optimization</span>
<span class="kn">from</span> <span class="nn">trieste.acquisition</span> <span class="kn">import</span> <span class="n">LocalPenalization</span>
<span class="kn">from</span> <span class="nn">trieste.acquisition.rule</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AsynchronousGreedy</span><span class="p">,</span>
    <span class="n">EfficientGlobalOptimization</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">trieste.ask_tell_optimization</span> <span class="kn">import</span> <span class="n">AskTellOptimizer</span>
</pre></div>
</div>
</div>
<div class="section" id="Multiprocessing-setup">
<h2>Multiprocessing setup<a class="headerlink" href="#Multiprocessing-setup" title="Permalink to this headline">#</a></h2>
<p>To keep this notebook as reproducible as possible, we will only be using Python’s multiprocessing package here. In this section we will explain our setup and define some common code to be used later.</p>
<p>In both synchronous and asynchronous scenarios we will have a fixed set of worker processes performing observations. We will also have a main process responsible for optimization process with Trieste. When Trieste suggests a new point, it is inserted into a points queue. One of the workers picks this point from the queue, performs the observation, and inserts the output into the observations queue. The main process then picks up the observation from the queue, at which moment it either waits for
the rest of the points in the batch to come back (synchronous scenario) or immediately suggests a new point (asynchronous scenario). This process continues either for a certain number of iterations or until we accumulate necessary number of observations.</p>
<p>The overall setup is illustrated in this diagram: <img alt="multiprocessing setup" src="../_images/async_bo.png" /></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Necessary multiprocessing primitives</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Manager</span><span class="p">,</span> <span class="n">Process</span>
</pre></div>
</div>
</div>
<p>We now define several common functions to implement the described setup. First we define a worker function that will be running a single observation in a separate process. Worker takes both queues as an input, reads next point from the points queue, makes an observation, and inserts observed data into the observations queue.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><br/><span></span><span class="k">def</span> <span class="nf">observer_proc</span><span class="p">(</span><span class="n">points_queue</span><span class="p">,</span> <span class="n">observations_queue</span><span class="p">):</span>
    <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">point_to_observe</span> <span class="o">=</span> <span class="n">points_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">point_to_observe</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">: Observer : observing data at point </span><span class="si">{</span><span class="n">point_to_observe</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">new_observation</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">point_to_observe</span><span class="p">,</span> <span class="n">sleep</span><span class="o">=</span><span class="n">enable_sleep_delays</span><span class="p">)</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">point_to_observe</span><span class="p">,</span> <span class="n">new_observation</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">: Observer : observed data </span><span class="si">{</span><span class="n">new_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">observations_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next we define two helper functions, one is to create a certain number of worker processes, and another is to terminate them once we are done.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><br/><span></span><span class="k">def</span> <span class="nf">create_worker_processes</span><span class="p">(</span><span class="n">n_workers</span><span class="p">,</span> <span class="n">points_queue</span><span class="p">,</span> <span class="n">obseverations_queue</span><span class="p">):</span>
    <span class="n">observer_processes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_workers</span><span class="p">):</span>
        <span class="n">worker_proc</span> <span class="o">=</span> <span class="n">Process</span><span class="p">(</span>
            <span class="n">target</span><span class="o">=</span><span class="n">observer_proc</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">points_queue</span><span class="p">,</span> <span class="n">obseverations_queue</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">worker_proc</span><span class="o">.</span><span class="n">daemon</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">worker_proc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

        <span class="n">observer_processes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">worker_proc</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">observer_processes</span>


<span class="k">def</span> <span class="nf">terminate_processes</span><span class="p">(</span><span class="n">processes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">prc</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
        <span class="n">prc</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
        <span class="n">prc</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
        <span class="n">prc</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Finally we set some common parameters. See comments below for explanation of what each one means.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of worker processes to run simultaneously</span>
<span class="c1"># Setting this to 1 will turn both setups into non-batch sequential optimization</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">3</span>
<span class="c1"># Number of iterations to run the sycnhronous scenario for</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># Number of observations to collect in the asynchronous scenario</span>
<span class="n">num_observations</span> <span class="o">=</span> <span class="n">num_workers</span> <span class="o">*</span> <span class="n">num_iterations</span>
<span class="c1"># Set this flag to False to disable sleep delays in case you want the notebook to execute quickly</span>
<span class="n">enable_sleep_delays</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Asynchronous-optimization">
<h2>Asynchronous optimization<a class="headerlink" href="#Asynchronous-optimization" title="Permalink to this headline">#</a></h2>
<p>This section runs the asynchronous optimization routine. We first setup the <a class="reference internal" href="ask_tell_optimization.html"><span class="doc">ask/tell optimizer</span></a> as we cannot hand over the evaluation of the objective to Trieste. Next we create thread-safe queues for points and observations, and run the optimization loop.</p>
<p>Crucially, even though we are using batch acquisition function Local Penalization, we specify batch size of 1. This is because we don’t really want a batch. Since the amount of workers we have is fixed, whenever we see a new observation we only need one point back. However this process can only be done with acquisition functions that implement greedy batch collection strategies, because they are able to take into account points that are currently being observed (in Trieste we call them
“pending”). Trieste currently provides two such functions: Local Penalization and GIBBON. Notice that we use <strong>AsynchronousGreedy</strong> rule specifically designed for using greedy batch acquisition functions in asynchronous scenarios.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="c1"># setup Ask Tell BO</span>
<span class="n">local_penalization_acq</span> <span class="o">=</span> <span class="n">LocalPenalization</span><span class="p">(</span><span class="n">search_space</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
<span class="n">local_penalization_rule</span> <span class="o">=</span> <span class="n">AsynchronousGreedy</span><span class="p">(</span><span class="n">builder</span><span class="o">=</span><span class="n">local_penalization_acq</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

<span class="n">async_bo</span> <span class="o">=</span> <span class="n">AskTellOptimizer</span><span class="p">(</span>
    <span class="n">search_space</span><span class="p">,</span> <span class="n">initial_data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">local_penalization_rule</span>
<span class="p">)</span>

<span class="c1"># retrieve process id for nice logging</span>
<span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
<span class="c1"># create point and observation queues</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">Manager</span><span class="p">()</span>
<span class="n">pq</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
<span class="n">oq</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
<span class="c1"># keep track of all workers we have launched</span>
<span class="n">observer_processes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># counter to keep track of collected observations</span>
<span class="n">points_observed</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">observer_processes</span> <span class="o">=</span> <span class="n">create_worker_processes</span><span class="p">(</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">pq</span><span class="p">,</span> <span class="n">oq</span><span class="p">)</span>

    <span class="c1"># init the queue with first batch of points</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_workers</span><span class="p">):</span>
        <span class="n">point</span> <span class="o">=</span> <span class="n">async_bo</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
        <span class="n">pq</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">point</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>

    <span class="k">while</span> <span class="n">points_observed</span> <span class="o">&lt;</span> <span class="n">num_observations</span><span class="p">:</span>
        <span class="c1"># keep asking queue for new observations until one arrives</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">new_data</span> <span class="o">=</span> <span class="n">oq</span><span class="o">.</span><span class="n">get_nowait</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">: Main     : received data </span><span class="si">{</span><span class="n">new_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="c1"># new_data is a tuple of (point, observation value)</span>
        <span class="c1"># here we turn it into a Dataset and tell of it Trieste</span>
        <span class="n">points_observed</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">query_points</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">new_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
            <span class="n">observations</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">new_data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">async_bo</span><span class="o">.</span><span class="n">tell</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>

        <span class="c1"># now we can ask Trieste for one more point</span>
        <span class="c1"># and feed that back into the points queue</span>
        <span class="n">point</span> <span class="o">=</span> <span class="n">async_bo</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">: Main     : acquired point </span><span class="si">{</span><span class="n">point</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">pq</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">point</span><span class="p">))</span>
<span class="k">finally</span><span class="p">:</span>
    <span class="n">terminate_processes</span><span class="p">(</span><span class="n">observer_processes</span><span class="p">)</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">default_timer</span><span class="p">()</span>

<span class="c1"># Collect the observations, compute the running time</span>
<span class="n">async_lp_observations</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">async_bo</span><span class="o">.</span><span class="n">to_result</span><span class="p">()</span><span class="o">.</span><span class="n">try_get_final_dataset</span><span class="p">()</span><span class="o">.</span><span class="n">observations</span>
    <span class="o">-</span> <span class="n">ScaledBranin</span><span class="o">.</span><span class="n">minimum</span>
<span class="p">)</span>
<span class="n">async_lp_time</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">async_lp_observations</span><span class="p">)</span><span class="si">}</span><span class="s2"> observations in </span><span class="si">{</span><span class="n">async_lp_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Process 2672: Observer : observing data at point [[0.39121406 0.43988542]]
Process 2672: Objective: pretends like it&#39;s doing something for 2.5s
Process 2676: Observer : observing data at point [[0.47136974 0.38261521]]
Process 2676: Objective: pretends like it&#39;s doing something for 2.6s
Process 2680: Observer : observing data at point [[0.31920444 0.47486873]]
Process 2680: Objective: pretends like it&#39;s doing something for 2.4s
Process 2672: Observer : observed data (array([[0.39121406, 0.43988542]]), array([[-0.67489141]]))
Process 2632: Main     : received data (array([[0.39121406, 0.43988542]]), array([[-0.67489141]]))
Process 2676: Observer : observed data (array([[0.47136974, 0.38261521]]), array([[-0.83266931]]))
Process 2680: Observer : observed data (array([[0.31920444, 0.47486873]]), array([[-0.67015284]]))
Process 2632: Main     : acquired point [[0.58933802 0.39929895]]
Process 2632: Main     : received data (array([[0.47136974, 0.38261521]]), array([[-0.83266931]]))
Process 2672: Observer : observing data at point [[0.58933802 0.39929895]]
Process 2672: Objective: pretends like it&#39;s doing something for 3.0s
Process 2632: Main     : acquired point [[0.52087536 0.35096195]]
Process 2632: Main     : received data (array([[0.31920444, 0.47486873]]), array([[-0.67015284]]))
Process 2676: Observer : observing data at point [[0.52087536 0.35096195]]Process 2676: Objective: pretends like it&#39;s doing something for 2.6s

Process 2672: Observer : observed data (array([[0.58933802, 0.39929895]]), array([[-0.66517114]]))
Process 2632: Main     : acquired point [[0.47991382 0.33917611]]
Process 2632: Main     : received data (array([[0.58933802, 0.39929895]]), array([[-0.66517114]]))
Process 2680: Observer : observing data at point [[0.47991382 0.33917611]]
Process 2680: Objective: pretends like it&#39;s doing something for 2.5s
Process 2632: Main     : acquired point [[0.43935279 0.3371416 ]]
Process 2672: Observer : observing data at point [[0.43935279 0.3371416 ]]
Process 2676: Observer : observed data (array([[0.52087536, 0.35096195]]), array([[-0.8951681]]))Process 2672: Objective: pretends like it&#39;s doing something for 2.3s

Process 2632: Main     : received data (array([[0.52087536, 0.35096195]]), array([[-0.8951681]]))
Process 2680: Observer : observed data (array([[0.47991382, 0.33917611]]), array([[-0.89700689]]))
Process 2632: Main     : acquired point [[0.50656592 0.31252904]]
Process 2632: Main     : received data (array([[0.47991382, 0.33917611]]), array([[-0.89700689]]))
Process 2676: Observer : observing data at point [[0.50656592 0.31252904]]
Process 2676: Objective: pretends like it&#39;s doing something for 2.5s
Process 2672: Observer : observed data (array([[0.43935279, 0.3371416 ]]), array([[-0.83553327]]))
Process 2632: Main     : acquired point [[0.50671    0.32942255]]
Process 2632: Main     : received data (array([[0.43935279, 0.3371416 ]]), array([[-0.83553327]]))
Process 2680: Observer : observing data at point [[0.50671    0.32942255]]
Process 2680: Objective: pretends like it&#39;s doing something for 2.5s
Process 2676: Observer : observed data (array([[0.50656592, 0.31252904]]), array([[-0.94750593]]))
Process 2632: Main     : acquired point [[0.52312793 0.30919962]]
Process 2672: Observer : observing data at point [[0.52312793 0.30919962]]Process 2632: Main     : received data (array([[0.50656592, 0.31252904]]), array([[-0.94750593]]))


Process 2672: Objective: pretends like it&#39;s doing something for 2.5sProcess 2680: Observer : observed data (array([[0.50671   , 0.32942255]]), array([[-0.92727109]]))
Process 2632: Main     : acquired point [[0.5290684  0.27412684]]
Process 2632: Main     : received data (array([[0.50671   , 0.32942255]]), array([[-0.92727109]]))
Process 2676: Observer : observing data at point [[0.5290684  0.27412684]]
Process 2676: Objective: pretends like it&#39;s doing something for 2.4s
Process 2672: Observer : observed data (array([[0.52312793, 0.30919962]]), array([[-0.95275195]]))
Process 2632: Main     : acquired point [[0.52772643 0.25870545]]
Process 2680: Observer : observing data at point [[0.52772643 0.25870545]]Process 2632: Main     : received data (array([[0.52312793, 0.30919962]]), array([[-0.95275195]]))

Process 2680: Objective: pretends like it&#39;s doing something for 2.4s
Process 2676: Observer : observed data (array([[0.5290684 , 0.27412684]]), array([[-0.98974529]]))
Process 2632: Main     : acquired point [[0.51915248 0.2700293 ]]
Process 2632: Main     : received data (array([[0.5290684 , 0.27412684]]), array([[-0.98974529]]))
Process 2672: Observer : observing data at point [[0.51915248 0.2700293 ]]
Process 2672: Objective: pretends like it&#39;s doing something for 2.4s
Process 2680: Observer : observed data (array([[0.52772643, 0.25870545]]), array([[-1.00372836]]))
Process 2632: Main     : acquired point [[0.53654317 0.22302654]]
Process 2632: Main     : received data (array([[0.52772643, 0.25870545]]), array([[-1.00372836]]))
Process 2676: Observer : observing data at point [[0.53654317 0.22302654]]
Process 2676: Objective: pretends like it&#39;s doing something for 2.3s
Process 2672: Observer : observed data (array([[0.51915248, 0.2700293 ]]), array([[-0.9935836]]))
Process 2632: Main     : acquired point [[0.53912772 0.19384463]]
Process 2632: Main     : received data (array([[0.51915248, 0.2700293 ]]), array([[-0.9935836]]))
Process 2680: Observer : observing data at point [[0.53912772 0.19384463]]
Process 2680: Objective: pretends like it&#39;s doing something for 2.2s
Process 2676: Observer : observed data (array([[0.53654317, 0.22302654]]), array([[-1.02747672]]))
Process 2632: Main     : acquired point [[0.54156875 0.18477669]]
Process 2632: Main     : received data (array([[0.53654317, 0.22302654]]), array([[-1.02747672]]))
Process 2672: Observer : observing data at point [[0.54156875 0.18477669]]
Process 2672: Objective: pretends like it&#39;s doing something for 2.2s
Process 2680: Observer : observed data (array([[0.53912772, 0.19384463]]), array([[-1.04042511]]))
Process 2632: Main     : acquired point [[0.55718208 0.140132  ]]
Process 2676: Observer : observing data at point [[0.55718208 0.140132  ]]Process 2632: Main     : received data (array([[0.53912772, 0.19384463]]), array([[-1.04042511]]))

Process 2676: Objective: pretends like it&#39;s doing something for 2.1s
Process 2672: Observer : observed data (array([[0.54156875, 0.18477669]]), array([[-1.04288197]]))
Process 2632: Main     : acquired point [[0.61094745 0.01405923]]
Process 2632: Main     : received data (array([[0.54156875, 0.18477669]]), array([[-1.04288197]]))
Process 2680: Observer : observing data at point [[0.61094745 0.01405923]]
Process 2680: Objective: pretends like it&#39;s doing something for 1.9s
Process 2676: Observer : observed data (array([[0.55718208, 0.140132  ]]), array([[-1.04309121]]))
Process 2632: Main     : acquired point [[0.65915737 0.        ]]
Process 2632: Main     : received data (array([[0.55718208, 0.140132  ]]), array([[-1.04309121]]))
Process 2672: Observer : observing data at point [[0.65915737 0.        ]]
Process 2672: Objective: pretends like it&#39;s doing something for 2.0s
Process 2680: Observer : observed data (array([[0.61094745, 0.01405923]]), array([[-0.92106233]]))
Process 2632: Main     : acquired point [[0.02841421 0.65983429]]
Process 2632: Main     : received data (array([[0.61094745, 0.01405923]]), array([[-0.92106233]]))
Process 2676: Observer : observing data at point [[0.02841421 0.65983429]]
Process 2676: Objective: pretends like it&#39;s doing something for 2.1s
Process 2672: Observer : observed data (array([[0.65915737, 0.        ]]), array([[-0.79748846]]))
Process 2632: Main     : acquired point [[0.02447911 0.86326405]]
Process 2632: Main     : received data (array([[0.65915737, 0.        ]]), array([[-0.79748846]]))
Process 2680: Observer : observing data at point [[0.02447911 0.86326405]]
Process 2680: Objective: pretends like it&#39;s doing something for 2.7s
Process 2676: Observer : observed data (array([[0.02841421, 0.65983429]]), array([[-0.17549631]]))
Process 2632: Main     : acquired point [[0.54479164 0.1539083 ]]
Process 2632: Main     : received data (array([[0.02841421, 0.65983429]]), array([[-0.17549631]]))
Process 2672: Observer : observing data at point [[0.54479164 0.1539083 ]]
Process 2672: Objective: pretends like it&#39;s doing something for 2.1s
Process 2680: Observer : observed data (array([[0.02447911, 0.86326405]]), array([[-0.68050074]]))
Process 2632: Main     : acquired point [[0.54484883 0.15550696]]
Process 2632: Main     : received data (array([[0.02447911, 0.86326405]]), array([[-0.68050074]]))
Process 2676: Observer : observing data at point [[0.54484883 0.15550696]]
Process 2676: Objective: pretends like it&#39;s doing something for 2.1s
Process 2672: Observer : observed data (array([[0.54479164, 0.1539083 ]]), array([[-1.04724634]]))
Process 2632: Main     : acquired point [[0.1531134 1.       ]]
Process 2680: Observer : observing data at point [[0.1531134 1.       ]]Process 2632: Main     : received data (array([[0.54479164, 0.1539083 ]]), array([[-1.04724634]]))

Process 2680: Objective: pretends like it&#39;s doing something for 3.5s
Process 2676: Observer : observed data (array([[0.54484883, 0.15550696]]), array([[-1.04717559]]))
Process 2632: Main     : acquired point [[0.23264258 1.        ]]
Process 2632: Main     : received data (array([[0.54484883, 0.15550696]]), array([[-1.04717559]]))
Process 2672: Observer : observing data at point [[0.23264258 1.        ]]
Process 2672: Objective: pretends like it&#39;s doing something for 3.7s
Process 2632: Main     : acquired point [[0.08677573 1.        ]]
Process 2676: Observer : observing data at point [[0.08677573 1.        ]]
Process 2676: Objective: pretends like it&#39;s doing something for 3.3s
Process 2680: Observer : observed data (array([[0.1531134, 1.       ]]), array([[-0.75872322]]))
Process 2632: Main     : received data (array([[0.1531134, 1.       ]]), array([[-0.75872322]]))
Process 2632: Main     : acquired point [[1. 1.]]
Process 2680: Observer : observing data at point [[1. 1.]]
Process 2680: Objective: pretends like it&#39;s doing something for 6.0s
Process 2672: Observer : observed data (array([[0.23264258, 1.        ]]), array([[-0.08703106]]))
Process 2632: Main     : received data (array([[0.23264258, 1.        ]]), array([[-0.08703106]]))
Process 2676: Observer : observed data (array([[0.08677573, 1.        ]]), array([[-0.98455686]]))
Process 2632: Main     : acquired point [[0.06579332 1.        ]]
Process 2672: Observer : observing data at point [[0.06579332 1.        ]]
Process 2632: Main     : received data (array([[0.08677573, 1.        ]]), array([[-0.98455686]]))
Process 2672: Objective: pretends like it&#39;s doing something for 3.2s
Process 2632: Main     : acquired point [[1. 0.]]
Process 2676: Observer : observing data at point [[1. 0.]]
Process 2676: Objective: pretends like it&#39;s doing something for 3.0s
Process 2672: Observer : observed data (array([[0.06579332, 1.        ]]), array([[-0.97607573]]))
Process 2632: Main     : received data (array([[0.06579332, 1.        ]]), array([[-0.97607573]]))
Process 2676: Observer : observed data (array([[1., 0.]]), array([[-0.84406373]]))
Process 2680: Observer : observed data (array([[1., 1.]]), array([[1.75288144]]))
Process 2632: Main     : acquired point [[1.         0.21561138]]
Process 2632: Main     : received data (array([[1., 0.]]), array([[-0.84406373]]))
Process 2672: Observer : observing data at point [[1.         0.21561138]]
Process 2672: Objective: pretends like it&#39;s doing something for 3.6s
Process 2632: Main     : acquired point [[1.         0.46875531]]
Process 2632: Main     : received data (array([[1., 1.]]), array([[1.75288144]]))
Process 2676: Observer : observing data at point [[1.         0.46875531]]

Process 2676: Objective: pretends like it&#39;s doing something for 4.4sProcess 2632: Main     : acquired point [[0.89136777 0.        ]]
Process 2680: Observer : observing data at point [[0.89136777 0.        ]]
Process 2680: Objective: pretends like it&#39;s doing something for 2.7s
Process 2672: Observer : observed data (array([[1.        , 0.21561138]]), array([[-1.01661981]]))
Process 2632: Main     : received data (array([[1.        , 0.21561138]]), array([[-1.01661981]]))
Process 2632: Main     : acquired point [[0.92819921 0.17288983]]
Got 33 observations in 50.03s
</pre></div></div>
</div>
</div>
<div class="section" id="Synchronous-parallel-optimization">
<h2>Synchronous parallel optimization<a class="headerlink" href="#Synchronous-parallel-optimization" title="Permalink to this headline">#</a></h2>
<p>This section runs the synchronous parallel optimization with Trieste. We again use Local Penalization acquisition function, but this time with batch size equal to the number of workers we have available. Once Trieste suggests the batch, we add all points to the point queue, and workers immediatelly pick them up, one point per worker. Therefore all points in the batch are evaluated in parallel.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># setup Ask Tell BO</span>
<span class="n">gpflow_model</span> <span class="o">=</span> <span class="n">build_gpr</span><span class="p">(</span><span class="n">initial_data</span><span class="p">,</span> <span class="n">search_space</span><span class="p">,</span> <span class="n">likelihood_variance</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianProcessRegression</span><span class="p">(</span><span class="n">gpflow_model</span><span class="p">)</span>

<span class="n">local_penalization_acq</span> <span class="o">=</span> <span class="n">LocalPenalization</span><span class="p">(</span><span class="n">search_space</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
<span class="n">local_penalization_rule</span> <span class="o">=</span> <span class="n">EfficientGlobalOptimization</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
    <span class="n">num_query_points</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">builder</span><span class="o">=</span><span class="n">local_penalization_acq</span>
<span class="p">)</span>

<span class="n">sync_bo</span> <span class="o">=</span> <span class="n">AskTellOptimizer</span><span class="p">(</span>
    <span class="n">search_space</span><span class="p">,</span> <span class="n">initial_data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">local_penalization_rule</span>
<span class="p">)</span>


<span class="c1"># retrieve process id for nice logging</span>
<span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
<span class="c1"># create point and observation queues</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">Manager</span><span class="p">()</span>
<span class="n">pq</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
<span class="n">oq</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">Queue</span><span class="p">()</span>
<span class="c1"># keep track of all workers we have launched</span>
<span class="n">observer_processes</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">observer_processes</span> <span class="o">=</span> <span class="n">create_worker_processes</span><span class="p">(</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">pq</span><span class="p">,</span> <span class="n">oq</span><span class="p">)</span>

    <span class="c1"># BO loop starts here</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">: Main     : iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> starts&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># get a batch of points from Trieste, send them to points queue</span>
        <span class="c1"># each worker picks up a point and processes it</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">sync_bo</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span><span class="o">.</span><span class="n">numpy</span><span class="p">():</span>
            <span class="n">pq</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">point</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># reshape is to make point a 2d array</span>

        <span class="c1"># now we wait for all workers to finish</span>
        <span class="c1"># we create an empty dataset and wait</span>
        <span class="c1"># until we collected as many observations in it</span>
        <span class="c1"># as there were points in the batch</span>
        <span class="n">all_new_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">initial_data</span><span class="o">.</span><span class="n">query_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">initial_data</span><span class="o">.</span><span class="n">observations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_new_data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_workers</span><span class="p">:</span>
            <span class="c1"># this line blocks the process until new data is available in the queue</span>
            <span class="n">new_data</span> <span class="o">=</span> <span class="n">oq</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">: Main     : received data </span><span class="si">{</span><span class="n">new_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">new_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
                <span class="n">query_points</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">new_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
                <span class="n">observations</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">new_data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
            <span class="p">)</span>

            <span class="n">all_new_data</span> <span class="o">=</span> <span class="n">all_new_data</span> <span class="o">+</span> <span class="n">new_data</span>

        <span class="c1"># tell Trieste of new batch of observations</span>
        <span class="n">sync_bo</span><span class="o">.</span><span class="n">tell</span><span class="p">(</span><span class="n">all_new_data</span><span class="p">)</span>

<span class="k">finally</span><span class="p">:</span>
    <span class="n">terminate_processes</span><span class="p">(</span><span class="n">observer_processes</span><span class="p">)</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">default_timer</span><span class="p">()</span>

<span class="c1"># Collect the observations, compute the running time</span>
<span class="n">sync_lp_observations</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">sync_bo</span><span class="o">.</span><span class="n">to_result</span><span class="p">()</span><span class="o">.</span><span class="n">try_get_final_dataset</span><span class="p">()</span><span class="o">.</span><span class="n">observations</span>
    <span class="o">-</span> <span class="n">ScaledBranin</span><span class="o">.</span><span class="n">minimum</span>
<span class="p">)</span>
<span class="n">sync_lp_time</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sync_lp_observations</span><span class="p">)</span><span class="si">}</span><span class="s2"> observations in </span><span class="si">{</span><span class="n">sync_lp_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Process 2632: Main     : iteration 0 starts
Process 3100: Observer : observing data at point [[0.3907864  0.44030229]]Process 3108: Observer : observing data at point [[0.47120308 0.38212475]]
Process 3104: Observer : observing data at point [[0.31818249 0.47538159]]
Process 3100: Objective: pretends like it&#39;s doing something for 2.5s

Process 3108: Objective: pretends like it&#39;s doing something for 2.6sProcess 3104: Objective: pretends like it&#39;s doing something for 2.4s

Process 3104: Observer : observed data (array([[0.31818249, 0.47538159]]), array([[-0.67129177]]))
Process 2632: Main     : received data (array([[0.31818249, 0.47538159]]), array([[-0.67129177]]))
Process 3100: Observer : observed data (array([[0.3907864 , 0.44030229]]), array([[-0.67417172]]))
Process 2632: Main     : received data (array([[0.3907864 , 0.44030229]]), array([[-0.67417172]]))
Process 3108: Observer : observed data (array([[0.47120308, 0.38212475]]), array([[-0.83321652]]))
Process 2632: Main     : received data (array([[0.47120308, 0.38212475]]), array([[-0.83321652]]))
Process 2632: Main     : iteration 1 starts
Process 3108: Observer : observing data at point [[0.4890903  0.34213588]]Process 3104: Observer : observing data at point [[0.53896099 0.35712759]]
Process 3100: Observer : observing data at point [[0.59060681 0.36191239]]
Process 3108: Objective: pretends like it&#39;s doing something for 2.5s
Process 3104: Objective: pretends like it&#39;s doing something for 2.7s
Process 3100: Objective: pretends like it&#39;s doing something for 2.9s

Process 3108: Observer : observed data (array([[0.4890903 , 0.34213588]]), array([[-0.90204745]]))
Process 2632: Main     : received data (array([[0.4890903 , 0.34213588]]), array([[-0.90204745]]))
Process 3104: Observer : observed data (array([[0.53896099, 0.35712759]]), array([[-0.86956023]]))
Process 2632: Main     : received data (array([[0.53896099, 0.35712759]]), array([[-0.86956023]]))
Process 3100: Observer : observed data (array([[0.59060681, 0.36191239]]), array([[-0.74583233]]))
Process 2632: Main     : received data (array([[0.59060681, 0.36191239]]), array([[-0.74583233]]))
Process 2632: Main     : iteration 2 starts
Process 3100: Observer : observing data at point [[0.50688423 0.33169152]]Process 3108: Observer : observing data at point [[0.51070081 0.31595639]]Process 3104: Observer : observing data at point [[0.51524274 0.29809617]]


Process 3104: Objective: pretends like it&#39;s doing something for 2.4sProcess 3100: Objective: pretends like it&#39;s doing something for 2.5s

Process 3108: Objective: pretends like it&#39;s doing something for 2.5s
Process 3104: Observer : observed data (array([[0.51524274, 0.29809617]]), array([[-0.96580735]]))
Process 2632: Main     : received data (array([[0.51524274, 0.29809617]]), array([[-0.96580735]]))
Process 3108: Observer : observed data (array([[0.51070081, 0.31595639]]), array([[-0.94478587]]))
Process 2632: Main     : received data (array([[0.51070081, 0.31595639]]), array([[-0.94478587]]))
Process 3100: Observer : observed data (array([[0.50688423, 0.33169152]]), array([[-0.92439827]]))
Process 2632: Main     : received data (array([[0.50688423, 0.33169152]]), array([[-0.92439827]]))
Process 2632: Main     : iteration 3 starts
Process 3108: Observer : observing data at point [[0.53090584 0.23964148]]Process 3100: Observer : observing data at point [[0.5245819  0.26047016]]Process 3104: Observer : observing data at point [[0.52738084 0.25040196]]

Process 3100: Objective: pretends like it&#39;s doing something for 2.4sProcess 3108: Objective: pretends like it&#39;s doing something for 2.3s


Process 3104: Objective: pretends like it&#39;s doing something for 2.3s
Process 3108: Observer : observed data (array([[0.53090584, 0.23964148]]), array([[-1.01781987]]))
Process 2632: Main     : received data (array([[0.53090584, 0.23964148]]), array([[-1.01781987]]))
Process 3104: Observer : observed data (array([[0.52738084, 0.25040196]]), array([[-1.01025327]]))
Process 2632: Main     : received data (array([[0.52738084, 0.25040196]]), array([[-1.01025327]]))
Process 3100: Observer : observed data (array([[0.5245819 , 0.26047016]]), array([[-1.00230573]]))
Process 2632: Main     : received data (array([[0.5245819 , 0.26047016]]), array([[-1.00230573]]))
Process 2632: Main     : iteration 4 starts
Process 3108: Observer : observing data at point [[0.54576767 0.17603873]]Process 3100: Observer : observing data at point [[0.54334711 0.18689545]]
Process 3104: Observer : observing data at point [[0.54879462 0.1644474 ]]
Process 3108: Objective: pretends like it&#39;s doing something for 2.2s
Process 3100: Objective: pretends like it&#39;s doing something for 2.2s

Process 3104: Objective: pretends like it&#39;s doing something for 2.1s
Process 3104: Observer : observed data (array([[0.54879462, 0.1644474 ]]), array([[-1.04532811]]))
Process 2632: Main     : received data (array([[0.54879462, 0.1644474 ]]), array([[-1.04532811]]))
Process 3108: Observer : observed data (array([[0.54576767, 0.17603873]]), array([[-1.04412209]]))
Process 2632: Main     : received data (array([[0.54576767, 0.17603873]]), array([[-1.04412209]]))
Process 3100: Observer : observed data (array([[0.54334711, 0.18689545]]), array([[-1.04187453]]))
Process 2632: Main     : received data (array([[0.54334711, 0.18689545]]), array([[-1.04187453]]))
Process 2632: Main     : iteration 5 starts
Process 3108: Observer : observing data at point [[0.69681289 0.        ]]Process 3104: Observer : observing data at point [[0.63271604 0.        ]]

Process 3100: Observer : observing data at point [[0.53690397 0.13535989]]Process 3108: Objective: pretends like it&#39;s doing something for 2.1s

Process 3104: Objective: pretends like it&#39;s doing something for 1.9sProcess 3100: Objective: pretends like it&#39;s doing something for 2.0s

Process 3104: Observer : observed data (array([[0.63271604, 0.        ]]), array([[-0.86227443]]))
Process 2632: Main     : received data (array([[0.63271604, 0.        ]]), array([[-0.86227443]]))
Process 3100: Observer : observed data (array([[0.53690397, 0.13535989]]), array([[-1.04477714]]))
Process 2632: Main     : received data (array([[0.53690397, 0.13535989]]), array([[-1.04477714]]))
Process 3108: Observer : observed data (array([[0.69681289, 0.        ]]), array([[-0.71193061]]))
Process 2632: Main     : received data (array([[0.69681289, 0.        ]]), array([[-0.71193061]]))
Process 2632: Main     : iteration 6 starts
Process 3108: Observer : observing data at point [[0.54266847 0.1523495 ]]Process 3104: Observer : observing data at point [[0.54284892 0.15124097]]Process 3100: Observer : observing data at point [[0.54275641 0.1518078 ]]


Process 3108: Objective: pretends like it&#39;s doing something for 2.1s
Process 3104: Objective: pretends like it&#39;s doing something for 2.1s
Process 3100: Objective: pretends like it&#39;s doing something for 2.1s
Process 3108: Observer : observed data (array([[0.54266847, 0.1523495 ]]), array([[-1.0473921]]))Process 3104: Observer : observed data (array([[0.54284892, 0.15124097]]), array([[-1.04739319]]))
Process 2632: Main     : received data (array([[0.54284892, 0.15124097]]), array([[-1.04739319]]))
Process 3100: Observer : observed data (array([[0.54275641, 0.1518078 ]]), array([[-1.04739381]]))
Process 2632: Main     : received data (array([[0.54275641, 0.1518078 ]]), array([[-1.04739381]]))

Process 2632: Main     : received data (array([[0.54266847, 0.1523495 ]]), array([[-1.0473921]]))
Process 2632: Main     : iteration 7 starts
Process 3108: Observer : observing data at point [[0.00887375 0.45627981]]Process 3104: Observer : observing data at point [[0.04370284 0.62715216]]Process 3100: Observer : observing data at point [[0.03801823 0.81157673]]


Process 3100: Objective: pretends like it&#39;s doing something for 2.5sProcess 3104: Objective: pretends like it&#39;s doing something for 2.0s

Process 3108: Objective: pretends like it&#39;s doing something for 1.4s
Process 3108: Observer : observed data (array([[0.00887375, 0.45627981]]), array([[1.07607737]]))
Process 2632: Main     : received data (array([[0.00887375, 0.45627981]]), array([[1.07607737]]))
Process 3104: Observer : observed data (array([[0.04370284, 0.62715216]]), array([[-0.24862193]]))
Process 2632: Main     : received data (array([[0.04370284, 0.62715216]]), array([[-0.24862193]]))
Process 3100: Observer : observed data (array([[0.03801823, 0.81157673]]), array([[-0.69009663]]))
Process 2632: Main     : received data (array([[0.03801823, 0.81157673]]), array([[-0.69009663]]))
Process 2632: Main     : iteration 8 starts
Process 3100: Observer : observing data at point [[0.17253931 0.75919806]]Process 3104: Observer : observing data at point [[0.17811849 0.87694404]]Process 3108: Observer : observing data at point [[0.17189656 0.81437405]]
Process 3108: Objective: pretends like it&#39;s doing something for 3.0s
Process 3104: Objective: pretends like it&#39;s doing something for 3.2s



Process 3100: Objective: pretends like it&#39;s doing something for 2.8sProcess 3100: Observer : observed data (array([[0.17253931, 0.75919806]]), array([[-0.98808112]]))
Process 2632: Main     : received data (array([[0.17253931, 0.75919806]]), array([[-0.98808112]]))
Process 3108: Observer : observed data (array([[0.17189656, 0.81437405]]), array([[-0.95198534]]))
Process 2632: Main     : received data (array([[0.17189656, 0.81437405]]), array([[-0.95198534]]))
Process 3104: Observer : observed data (array([[0.17811849, 0.87694404]]), array([[-0.84414553]]))
Process 2632: Main     : received data (array([[0.17811849, 0.87694404]]), array([[-0.84414553]]))
Process 2632: Main     : iteration 9 starts
Process 3104: Observer : observing data at point [[1. 1.]]Process 3100: Observer : observing data at point [[1. 0.]]
Process 3108: Observer : observing data at point [[1.        0.2226434]]

Process 3108: Objective: pretends like it&#39;s doing something for 3.7sProcess 3100: Objective: pretends like it&#39;s doing something for 3.0s
Process 3104: Objective: pretends like it&#39;s doing something for 6.0s

Process 3100: Observer : observed data (array([[1., 0.]]), array([[-0.84406373]]))
Process 2632: Main     : received data (array([[1., 0.]]), array([[-0.84406373]]))
Process 3108: Observer : observed data (array([[1.       , 0.2226434]]), array([[-1.01546672]]))
Process 2632: Main     : received data (array([[1.       , 0.2226434]]), array([[-1.01546672]]))
Process 3104: Observer : observed data (array([[1., 1.]]), array([[1.75288144]]))
Process 2632: Main     : received data (array([[1., 1.]]), array([[1.75288144]]))
Got 33 observations in 46.56s
</pre></div></div>
</div>
</div>
<div class="section" id="Comparison">
<h2>Comparison<a class="headerlink" href="#Comparison" title="Permalink to this headline">#</a></h2>
<p>To compare outcomes of sync and async runs, let’s plot their respective regrets side by side, and print out the running time. For this toy problem we expect async scenario to run a little bit faster on machines with multiple CPU.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">trieste.experimental.plotting</span> <span class="kn">import</span> <span class="n">plot_regret</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">sync_lp_min_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">sync_lp_observations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">async_lp_min_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">async_lp_observations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">plot_regret</span><span class="p">(</span>
    <span class="n">sync_lp_observations</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">num_init</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">initial_data</span><span class="p">),</span>
    <span class="n">idx_best</span><span class="o">=</span><span class="n">sync_lp_min_idx</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Regret&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0000001</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;# evaluations&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Sync LP, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sync_lp_observations</span><span class="p">)</span><span class="si">}</span><span class="s2"> points, time </span><span class="si">{</span><span class="n">sync_lp_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>

<span class="n">plot_regret</span><span class="p">(</span>
    <span class="n">async_lp_observations</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">num_init</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">initial_data</span><span class="p">),</span>
    <span class="n">idx_best</span><span class="o">=</span><span class="n">async_lp_min_idx</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Regret&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0000001</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;# evaluations&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Async LP, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">async_lp_observations</span><span class="p">)</span><span class="si">}</span><span class="s2"> points, time </span><span class="si">{</span><span class="n">async_lp_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_asynchronous_greedy_multiprocessing_19_0.png" src="../_images/notebooks_asynchronous_greedy_multiprocessing_19_0.png" />
</div>
</div>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright Copyright 2020 The Trieste Contributors

Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>