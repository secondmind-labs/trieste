
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Asynchronous batch Bayesian optimization &#8212; trieste 1.0.0 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tracking and visualizing optimizations using Tensorboard" href="visualizing_with_tensorboard.html" />
    <link rel="prev" title="Asynchronous Bayesian optimization with Trieste" href="asynchronous_greedy_multiprocessing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  Trieste
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../autoapi/trieste/index.html">
  API reference
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-primary btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        1.0.0  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables notebooks/asynchronous_nongreedy_batch_ray and {'json_url': 'https://secondmind-labs.github.io/trieste/versions.json', 'version_match': '1.0.0'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "notebooks/asynchronous_nongreedy_batch_ray.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://secondmind-labs.github.io/trieste/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "notebooks/asynchronous_nongreedy_batch_ray.html";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "1.0.0") {
                node.classList.add("active");
                let btn = document.getElementById("version_switcher_button");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/secondmind-labs/trieste" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="expected_improvement.html">
   Noise-free optimization with Expected Improvement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="batch_optimization.html">
   Batch Bayesian Optimization with Batch Expected Improvement, Local Penalization, Kriging Believer and GIBBON
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="thompson_sampling.html">
   Batch-sequential optimization with Thompson sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="inequality_constraints.html">
   Inequality constraints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="explicit_constraints.html">
   Explicit Constraints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="failure_ego.html">
   EGO with a failure region
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multi_objective_ehvi.html">
   Multi-objective optimization with Expected HyperVolume Improvement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deep_gaussian_processes.html">
   Using deep Gaussian processes with GPflux for Bayesian optimization.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deep_ensembles.html">
   Bayesian optimization with deep ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="active_learning.html">
   Active Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="active_learning_for_binary_classification.html">
   Active Learning for Gaussian Process Classification Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feasible_sets.html">
   Bayesian active learning of failure or feasibility regions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openai_gym_lunar_lander.html">
   Trieste meets OpenAI Gym
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scalable_thompson_sampling_using_sparse_gaussian_processes.html">
   Scalable Thompson Sampling using Sparse Gaussian Process Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="qhsri-tutorial.html">
   Batch HSRI Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multifidelity_modelling.html">
   Multifidelity Modelling with Autoregressive Model
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ask_tell_optimization.html">
   Ask-Tell Optimization Interface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data_transformation.html">
   Data transformation with the help of Ask-Tell interface.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="recovering_from_errors.html">
   Recovering from errors during optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="asynchronous_greedy_multiprocessing.html">
   Asynchronous Bayesian optimization with Trieste
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Asynchronous batch Bayesian optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="visualizing_with_tensorboard.html">
   Tracking and visualizing optimizations using Tensorboard
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="code_overview.html">
   An overview of Trieste types
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#LICENSE">
   LICENSE
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Asynchronous-batch-Bayesian-optimization">
<h1>Asynchronous batch Bayesian optimization<a class="headerlink" href="#Asynchronous-batch-Bayesian-optimization" title="Permalink to this headline">#</a></h1>
<p>As shown in <a class="reference internal" href="asynchronous_greedy_multiprocessing.html"><span class="doc">Asynchronous Bayesian Optimization</span></a> tutorial, Trieste provides support for running observations asynchronously. In that tutorial we used a greedy batch acquisition function called Local Penalization, and requested one new point whenever an observation was received. We also used the Python multiprocessing module to run distributed observations in parallel.</p>
<p>Here, we demonstrate a slightly different way of doing asynchronous Bayesian optimization. First, we make use of a non-greedy batch acquisition function, known as Batch Monte Carlo Expected Improvement. Second, we wait for several workers to finish, and then launch a new batch of points. However, since our batch size is smaller than the number of workers available, this approach is a hybrid between completely asynchronous and completely synchronous batch optimization. Note that greed acquisition
functions also support batch sizes. Third, we use <a class="reference external" href="https://www.ray.io/">Ray</a> to hide away most of the complexity of managing distributed workloads. There is no hard dependency in Trieste on a particular tool for parallel processing, and other libraries, such as <a class="reference external" href="https://dask.org/">Dask</a>, can be used.</p>
<p>Together these two notebooks give a comprehensive overview of how to use Trieste in asynchronous scenarios.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># silence TF warnings and info messages, only print errors</span>
<span class="c1"># https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_CPP_MIN_LOG_LEVEL&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;3&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s2">&quot;ERROR&quot;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
</pre></div>
</div>
</div>
<p>Just as in the other <a class="reference internal" href="asynchronous_greedy_multiprocessing.html"><span class="doc">notebook on asynchronous optimization</span></a>, we use Branin function with delays.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">trieste.objectives</span> <span class="kn">import</span> <span class="n">ScaledBranin</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">sleep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Incorrect input shape, expected (*, 2), got </span><span class="si">{</span><span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">observations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">ScaledBranin</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">point</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">sleep</span><span class="p">:</span>
            <span class="c1"># insert some artificial delay that</span>
            <span class="c1"># increases linearly with the absolute value of points</span>
            <span class="c1"># which means our evaluations will take different time</span>
            <span class="n">delay</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">delay</span><span class="p">)</span>
        <span class="n">observations</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">point</span><span class="p">,</span> <span class="n">observation</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">observations</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s confirm our objective function works as expected</span>
<span class="n">objective</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]),</span> <span class="n">sleep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[(array([0.1, 0.5]), array([-0.42052567]))]
</pre></div></div>
</div>
<p>To turn our objective function into a Ray task, we wrap it in a function with appropriate decorator. We are not using anything beyond Ray tasks API in this tutorial, and refer interested readers to <a class="reference external" href="https://docs.ray.io/en/latest/walkthrough.html">Ray documentation</a> and <a class="reference external" href="https://github.com/anyscale/academy/blob/main/ray-crash-course/01-Ray-Tasks.ipynb">Ray crash course</a> for more details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@ray</span><span class="o">.</span><span class="n">remote</span>
<span class="k">def</span> <span class="nf">ray_objective</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">sleep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">objective</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">sleep</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We prepare the model and some initial data to kick-start the optimization process.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">trieste.space</span> <span class="kn">import</span> <span class="n">Box</span>
<span class="kn">from</span> <span class="nn">trieste.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">search_space</span> <span class="o">=</span> <span class="n">Box</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">num_initial_points</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">initial_query_points</span> <span class="o">=</span> <span class="n">search_space</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_initial_points</span><span class="p">)</span>
<span class="n">initial_observations</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">initial_query_points</span><span class="p">,</span> <span class="n">sleep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">initial_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
    <span class="n">query_points</span><span class="o">=</span><span class="n">initial_query_points</span><span class="p">,</span>
    <span class="n">observations</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
        <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">initial_observations</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">gpflow</span>
<span class="kn">from</span> <span class="nn">trieste.models.gpflow</span> <span class="kn">import</span> <span class="n">GaussianProcessRegression</span><span class="p">,</span> <span class="n">build_gpr</span>


<span class="c1"># We set the likelihood variance to a small number because</span>
<span class="c1"># we are dealing with a noise-free problem.</span>
<span class="n">gpflow_model</span> <span class="o">=</span> <span class="n">build_gpr</span><span class="p">(</span><span class="n">initial_data</span><span class="p">,</span> <span class="n">search_space</span><span class="p">,</span> <span class="n">likelihood_variance</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianProcessRegression</span><span class="p">(</span><span class="n">gpflow_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Here we set up the configuration of our optimization run. See comments below for details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of worker processes to run simultaneously</span>
<span class="c1"># Setting this to 1 will reduce our optimization to non-batch sequential</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">6</span>
<span class="c1"># Number of observations to collect</span>
<span class="n">num_observations</span> <span class="o">=</span> <span class="mi">30</span>
<span class="c1"># Batch size of the acquisition function. We will wait for that many workers to return before launching a new batch</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Set this flag to False to disable sleep delays in case you want the notebook to execute quickly</span>
<span class="n">enable_sleep_delays</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
<p>Now we are ready to define the optimizer. Notice how we set the acquisition function to be <code class="docutils literal notranslate"><span class="pre">BatchMonteCarloExpectedImprovement</span></code>. It is also the default function used by the <code class="docutils literal notranslate"><span class="pre">AsynchronousOptimization</span></code> rule, but here we specify it explicitly for clarity. We also set the batch size.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">trieste.acquisition.rule</span> <span class="kn">import</span> <span class="n">AsynchronousOptimization</span>
<span class="kn">from</span> <span class="nn">trieste.acquisition.function</span> <span class="kn">import</span> <span class="n">BatchMonteCarloExpectedImprovement</span>
<span class="kn">from</span> <span class="nn">trieste.ask_tell_optimization</span> <span class="kn">import</span> <span class="n">AskTellOptimizer</span>

<span class="n">monte_carlo_sample_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">acquisition_function</span> <span class="o">=</span> <span class="n">BatchMonteCarloExpectedImprovement</span><span class="p">(</span>
    <span class="n">sample_size</span><span class="o">=</span><span class="n">monte_carlo_sample_size</span>
<span class="p">)</span>
<span class="n">async_rule</span> <span class="o">=</span> <span class="n">AsynchronousOptimization</span><span class="p">(</span><span class="n">acquisition_function</span><span class="p">,</span> <span class="n">num_query_points</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<span class="n">async_bo</span> <span class="o">=</span> <span class="n">AskTellOptimizer</span><span class="p">(</span><span class="n">search_space</span><span class="p">,</span> <span class="n">initial_data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">async_rule</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Initialize Ray. This line will output the dashboard URL, which you can open in a separate tab to watch workers doing observations.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">ignore_reinit_error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2023-01-31 17:00:11,775 INFO worker.py:1535 -- Started a local Ray instance. View the dashboard at <span class="ansi-green-intense-fg ansi-bold">http://127.0.0.1:8265 </span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
    <div style="margin-left: 50px;display: flex;flex-direction: row;align-items: center">
        <h3 style="color: var(--jp-ui-font-color0)">Ray</h3>
        <svg version="1.1" id="ray" width="3em" viewBox="0 0 144.5 144.6" style="margin-left: 3em;margin-right: 3em">
            <g id="layer-1">
                <path fill="#00a2e9" class="st0" d="M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1
                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2
                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9
                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5
                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5
                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7
                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1
                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9
                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2
                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3
                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3
                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3
                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7
                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3
                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6
                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10
                    C71.6,134.6,71.7,134.6,71.8,134.6z"/>
            </g>
        </svg>
        <table>
            <tr>
                <td style="text-align: left"><b>Python version:</b></td>
                <td style="text-align: left"><b>3.7.15</b></td>
            </tr>
            <tr>
                <td style="text-align: left"><b>Ray version:</b></td>
                <td style="text-align: left"><b> 2.2.0</b></td>
            </tr>
            <tr>
    <td style="text-align: left"><b>Dashboard:</b></td>
    <td style="text-align: left"><b><a href="http://127.0.0.1:8265" target="_blank">http://127.0.0.1:8265</a></b></td>
</tr>

        </table>
    </div>
</div></div>
</div>
<p>Here is the main optimization loop. First we ask for several batches of points to make sure all allocated workers are busy. Then we keep waiting for the workers to complete their tasks. Whenever <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> of tasks came back, we tell Trieste new observations and ask for another batch of points.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">points_observed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">workers</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># a helper function to launch a worker for a numpy array representing a single point</span>
<span class="k">def</span> <span class="nf">launch_worker</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">worker</span> <span class="o">=</span> <span class="n">ray_objective</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">enable_sleep_delays</span><span class="p">)</span>
    <span class="n">workers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">worker</span><span class="p">)</span>


<span class="c1"># get first couple of batches of points and init all workers</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_workers</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)):</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">async_bo</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">launch_worker</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">points</span><span class="p">)</span>

<span class="n">finished_workers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">while</span> <span class="n">points_observed</span> <span class="o">&lt;</span> <span class="n">num_observations</span><span class="p">:</span>
    <span class="n">ready_workers</span><span class="p">,</span> <span class="n">remaining_workers</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">wait</span><span class="p">(</span><span class="n">workers</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">finished_workers</span> <span class="o">+=</span> <span class="n">ready_workers</span>
    <span class="n">workers</span> <span class="o">=</span> <span class="n">remaining_workers</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">finished_workers</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">batch_size</span><span class="p">:</span>
        <span class="k">continue</span>

    <span class="c1"># we saw enough results to ask for a new batch</span>

    <span class="n">new_observations</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">observation</span>
        <span class="k">for</span> <span class="n">worker</span> <span class="ow">in</span> <span class="n">finished_workers</span>
        <span class="k">for</span> <span class="n">observation</span> <span class="ow">in</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">worker</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># new_observations is a list of tuples (point, observation value)</span>
    <span class="c1"># here we turn it into a Dataset and tell it to Trieste</span>
    <span class="n">points_observed</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_observations</span><span class="p">)</span>
    <span class="n">new_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
        <span class="n">query_points</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
            <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">new_observations</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span>
        <span class="p">),</span>
        <span class="n">observations</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
            <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">new_observations</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">async_bo</span><span class="o">.</span><span class="n">tell</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>

    <span class="c1"># get a new batch of points</span>
    <span class="c1"># and launch workers for each point in the batch</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">async_bo</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">launch_worker</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">points</span><span class="p">)</span>
    <span class="n">finished_workers</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-yellow-fg">(raylet)</span> Invalid -W option ignored: invalid action: &#39;&#34;ignore&#34;&#39;
<span class="ansi-yellow-fg">(raylet)</span> [2023-01-31 17:01:11,755 E 3707 3707] (raylet) node_manager.cc:3097: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: bef093a90d243bb4d7144312b2435815d8d34e2ffaf7c79375eb0c8e, IP: 10.1.0.166) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.1.0.166`
<span class="ansi-yellow-fg">(raylet)</span>
<span class="ansi-yellow-fg">(raylet)</span> Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
<span class="ansi-yellow-fg">(raylet)</span> Invalid -W option ignored: invalid action: &#39;&#34;ignore&#34;&#39;
<span class="ansi-yellow-fg">(raylet)</span> Invalid -W option ignored: invalid action: &#39;&#34;ignore&#34;&#39;
<span class="ansi-yellow-fg">(raylet)</span> [2023-01-31 17:02:11,756 E 3707 3707] (raylet) node_manager.cc:3097: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: bef093a90d243bb4d7144312b2435815d8d34e2ffaf7c79375eb0c8e, IP: 10.1.0.166) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.1.0.166`
<span class="ansi-yellow-fg">(raylet)</span>
<span class="ansi-yellow-fg">(raylet)</span> Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
</pre></div></div>
</div>
<p>Let’s plot the objective function and the points the optimization procedure explored.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">trieste.experimental.plotting</span> <span class="kn">import</span> <span class="n">plot_function_2d</span><span class="p">,</span> <span class="n">plot_bo_points</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">async_bo</span><span class="o">.</span><span class="n">to_result</span><span class="p">()</span><span class="o">.</span><span class="n">try_get_final_dataset</span><span class="p">()</span>
<span class="n">arg_min_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">observations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">query_points</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">query_points</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">observations</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_function_2d</span><span class="p">(</span>
    <span class="n">ScaledBranin</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
    <span class="n">search_space</span><span class="o">.</span><span class="n">lower</span><span class="p">,</span>
    <span class="n">search_space</span><span class="o">.</span><span class="n">upper</span><span class="p">,</span>
    <span class="n">grid_density</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">contour</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plot_bo_points</span><span class="p">(</span>
    <span class="n">query_points</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">num_initial_points</span><span class="p">,</span> <span class="n">arg_min_idx</span><span class="p">,</span> <span class="n">c_pass</span><span class="o">=</span><span class="s2">&quot;tab:red&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_asynchronous_nongreedy_batch_ray_18_0.png" src="../_images/notebooks_asynchronous_nongreedy_batch_ray_18_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ray</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>  <span class="c1"># &quot;Undo ray.init()&quot;. Terminate all the processes started in this notebook.</span>
</pre></div>
</div>
</div>
<div class="section" id="LICENSE">
<h2>LICENSE<a class="headerlink" href="#LICENSE" title="Permalink to this headline">#</a></h2>
<p><a class="reference external" href="https://github.com/secondmind-labs/trieste/blob/develop/LICENSE">Apache License 2.0</a></p>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright Copyright 2020 The Trieste Contributors

Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>