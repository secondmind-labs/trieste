:orphan:

:py:mod:`trieste.models.gpflux.models`
======================================

.. py:module:: trieste.models.gpflux.models


Module Contents
---------------

.. py:class:: DeepGaussianProcess(model: DeepGP | Callable[[], DeepGP], optimizer: KerasOptimizer | None = None, num_rff_features: int = 1000, continuous_optimisation: bool = True)

   Bases: :py:obj:`trieste.models.gpflux.interface.GPfluxPredictor`, :py:obj:`trieste.models.interfaces.TrainableProbabilisticModel`, :py:obj:`trieste.models.interfaces.HasReparamSampler`, :py:obj:`trieste.models.interfaces.HasTrajectorySampler`

   A :class:`TrainableProbabilisticModel` wrapper for a GPflux :class:`~gpflux.models.DeepGP` with
   :class:`GPLayer` or :class:`LatentVariableLayer`: this class does not support e.g. keras layers.
   We provide simple architectures that can be used with this class in the `architectures.py` file.
   Note: the user should remember to set `tf.keras.backend.set_floatx()` with the desired value
   (consistent with GPflow) so that dtype errors do not occur.

   :param model: The underlying GPflux deep Gaussian process model. Passing in a named closure
       rather than a model can help when copying or serialising.
   :param optimizer: The optimizer configuration for training the model. Defaults to
       :class:`~trieste.models.optimizer.KerasOptimizer` wrapper with
       :class:`~tf.optimizers.Adam` optimizer. The ``optimizer`` argument to the wrapper is
       used when compiling the model and ``fit_args`` is a dictionary of arguments to be used
       in the Keras ``fit`` method. Defaults to 400 epochs, batch size of 1000, and verbose 0.
       A custom callback that reduces the optimizer learning rate is used as well. See
       https://keras.io/api/models/model_training_apis/#fit-method for a list of possible
       arguments.
   :param num_rff_features: The number of random Fourier features used to approximate the
       kernel when calling :meth:`trajectory_sampler`. We use a default of 1000 as it typically
       performs well for a wide range of kernels. Note that very smooth kernels (e.g. RBF) can
       be well-approximated with fewer features.
   :param continuous_optimisation: if True (default), the optimizer will keep track of the
       number of epochs across BO iterations and use this number as initial_epoch. This is
       essential to allow monitoring of model training across BO iterations.
   :raise ValueError: If ``model`` has unsupported layers, ``num_rff_features`` is less than 0,
       or if the ``optimizer`` is not of a supported type.

   .. py:method:: model_gpflux(self) -> gpflux.models.DeepGP
      :property:

      The underlying GPflux model.


   .. py:method:: model_keras(self) -> tensorflow.keras.Model
      :property:

      Returns the compiled Keras model for training.


   .. py:method:: sample(self, query_points: trieste.types.TensorType, num_samples: int) -> trieste.types.TensorType

      Return ``num_samples`` samples from the independent marginal distributions at
      ``query_points``.

      :param query_points: The points at which to sample, with shape [..., N, D].
      :param num_samples: The number of samples at each point.
      :return: The samples. For a predictive distribution with event shape E, this has shape
          [..., S, N] + E, where S is the number of samples.


   .. py:method:: reparam_sampler(self, num_samples: int) -> trieste.models.interfaces.ReparametrizationSampler[trieste.models.gpflux.interface.GPfluxPredictor]

      Return a reparametrization sampler for a :class:`DeepGaussianProcess` model.

      :param num_samples: The number of samples to obtain.
      :return: The reparametrization sampler.


   .. py:method:: trajectory_sampler(self) -> trieste.models.interfaces.TrajectorySampler[trieste.models.gpflux.interface.GPfluxPredictor]

      Return a trajectory sampler. For :class:`DeepGaussianProcess`, we build
      trajectories using the GPflux default sampler.

      :return: The trajectory sampler.


   .. py:method:: update(self, dataset: trieste.data.Dataset) -> None

      Update the model given the specified ``dataset``. Does not train the model.

      :param dataset: The data with which to update the model.


   .. py:method:: optimize(self, dataset: trieste.data.Dataset) -> None

      Optimize the model with the specified `dataset`.
      :param dataset: The data with which to optimize the `model`.



