
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Data transformation with the help of Ask-Tell interface. &#8212; trieste 1.1.2 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Recovering from errors during optimization" href="recovering_from_errors.html" />
    <link rel="prev" title="Ask-Tell Optimization Interface" href="ask_tell_optimization.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  Trieste
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../autoapi/trieste/index.html">
  API reference
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-primary btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        1.1.2  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables notebooks/data_transformation and {'json_url': 'https://secondmind-labs.github.io/trieste/versions.json', 'version_match': '1.1.2'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "notebooks/data_transformation.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://secondmind-labs.github.io/trieste/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "notebooks/data_transformation.html";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "1.1.2") {
                node.classList.add("active");
                let btn = document.getElementById("version_switcher_button");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/secondmind-labs/trieste" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="expected_improvement.html">
   Noise-free optimization with Expected Improvement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="batch_optimization.html">
   Batch Bayesian Optimization with Batch Expected Improvement, Local Penalization, Kriging Believer and GIBBON
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="thompson_sampling.html">
   Batch-sequential optimization with Thompson sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="inequality_constraints.html">
   Inequality constraints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="explicit_constraints.html">
   Explicit Constraints
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="failure_ego.html">
   EGO with a failure region
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multi_objective_ehvi.html">
   Multi-objective optimization with Expected HyperVolume Improvement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deep_gaussian_processes.html">
   Using deep Gaussian processes with GPflux for Bayesian optimization.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deep_ensembles.html">
   Bayesian optimization with deep ensembles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="active_learning.html">
   Active Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="active_learning_for_binary_classification.html">
   Active Learning for Gaussian Process Classification Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="feasible_sets.html">
   Bayesian active learning of failure or feasibility regions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openai_gym_lunar_lander.html">
   Trieste meets OpenAI Gym
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scalable_thompson_sampling_using_sparse_gaussian_processes.html">
   Scalable Thompson Sampling using Sparse Gaussian Process Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="qhsri-tutorial.html">
   Batch HSRI Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multifidelity_modelling.html">
   Multifidelity Modelling with Autoregressive Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rembo.html">
   High-dimensional Bayesian optimization with Random EMbedding Bayesian Optimization (REMBO).
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ask_tell_optimization.html">
   Ask-Tell Optimization Interface
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Data transformation with the help of Ask-Tell interface.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="recovering_from_errors.html">
   Recovering from errors during optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="asynchronous_greedy_multiprocessing.html">
   Asynchronous Bayesian optimization with Trieste
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="asynchronous_nongreedy_batch_ray.html">
   Asynchronous batch Bayesian optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="visualizing_with_tensorboard.html">
   Tracking and visualizing optimizations using Tensorboard
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="code_overview.html">
   An overview of Trieste types
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Data transformation with the help of Ask-Tell interface.
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Describe-the-problem">
     Describe the problem
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Collect-initial-points">
     Collect initial points
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Model-the-objective-function">
     Model the objective function
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Run-the-optimization-loop">
     Run the optimization loop
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Explore-the-results">
     Explore the results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Data-transformation-with-the-help-of-Ask-Tell-interface">
   Data transformation with the help of Ask-Tell interface
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#LICENSE">
     LICENSE
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Data-transformation-with-the-help-of-Ask-Tell-interface.">
<h1>Data transformation with the help of Ask-Tell interface.<a class="headerlink" href="#Data-transformation-with-the-help-of-Ask-Tell-interface." title="Permalink to this headline">#</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">gpflow</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>
<span class="kn">from</span> <span class="nn">trieste.experimental.plotting</span> <span class="kn">import</span> <span class="n">plot_regret</span>

<span class="kn">import</span> <span class="nn">trieste</span>
<span class="kn">from</span> <span class="nn">trieste.ask_tell_optimization</span> <span class="kn">import</span> <span class="n">AskTellOptimizer</span>
<span class="kn">from</span> <span class="nn">trieste.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">trieste.models.gpflow</span> <span class="kn">import</span> <span class="n">GaussianProcessRegression</span>
<span class="kn">from</span> <span class="nn">trieste.objectives</span> <span class="kn">import</span> <span class="n">Trid10</span>
<span class="kn">from</span> <span class="nn">trieste.objectives.utils</span> <span class="kn">import</span> <span class="n">mk_observer</span>
<span class="kn">from</span> <span class="nn">trieste.space</span> <span class="kn">import</span> <span class="n">Box</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1794</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1794</span><span class="p">)</span>

<span class="c1"># silence TF warnings and info messages, only print errors</span>
<span class="c1"># https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_CPP_MIN_LOG_LEVEL&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;3&quot;</span>
<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s2">&quot;ERROR&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Describe-the-problem">
<h2>Describe the problem<a class="headerlink" href="#Describe-the-problem" title="Permalink to this headline">#</a></h2>
<p>In this notebook, we show how to perform data transformation during Bayesian optimization. This is usually required by the models. A very common example is normalising the data before fitting the model, either min-max or standard normalization. This is usually done for numerical stability, or to improve or speed up the convergence.</p>
<p>In regression problems it is easy to perform data transformations as you do it once before training. In Bayesian optimization this is more complex, as the data added with each iteration and needs to be transformed as well before the model is updated. At the moment Trieste cannot do such transformations for the user. Luckily, this can be easily done by using the <a class="reference internal" href="ask_tell_optimization.html"><span class="doc">Ask-Tell interface</span></a>, as it provides greater control of the optimization loop. The disadvantage is that
it is up to the user to take care of all the data transformation.</p>
<p>As an example, we will be searching for a minimum of a 10-dimensional <a class="reference external" href="https://www.sfu.ca/~ssurjano/trid.html">Trid function</a>. The range of variation of the Trid function values is large. It varies from values of <span class="math notranslate nohighlight">\(10^5\)</span> to its global minimum <span class="math notranslate nohighlight">\(f(x^∗) = −210\)</span>. This large variation range makes it difficult for Bayesian optimization with Gaussian processes to find the global minimum. However, with data normalisation it becomes possible (see <span id="id1">[<a class="reference internal" href="../autoapi/trieste/index.html#id27" title="Ali Hebbal, Loic Brevault, Mathieu Balesdent, El-Ghazali Talbi, and Nouredine Melab. Bayesian optimization using deep Gaussian processes. arXiv preprint arXiv:1905.03350, 2019.">HBB+19</a>]</span>).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">function</span> <span class="o">=</span> <span class="n">Trid10</span><span class="o">.</span><span class="n">objective</span>
<span class="n">F_MINIMUM</span> <span class="o">=</span> <span class="n">Trid10</span><span class="o">.</span><span class="n">minimum</span>
<span class="n">search_space</span> <span class="o">=</span> <span class="n">Trid10</span><span class="o">.</span><span class="n">search_space</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Collect-initial-points">
<h2>Collect initial points<a class="headerlink" href="#Collect-initial-points" title="Permalink to this headline">#</a></h2>
<p>We set up the observer as usual over the Trid function search space, using Sobol sampling to sample the initial points.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_initial_points</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">observer</span> <span class="o">=</span> <span class="n">mk_observer</span><span class="p">(</span><span class="n">function</span><span class="p">)</span>

<span class="n">initial_query_points</span> <span class="o">=</span> <span class="n">search_space</span><span class="o">.</span><span class="n">sample_sobol</span><span class="p">(</span><span class="n">num_initial_points</span><span class="p">)</span>
<span class="n">initial_data</span> <span class="o">=</span> <span class="n">observer</span><span class="p">(</span><span class="n">initial_query_points</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Model-the-objective-function">
<h2>Model the objective function<a class="headerlink" href="#Model-the-objective-function" title="Permalink to this headline">#</a></h2>
<p>The Bayesian optimization procedure estimates the next best points to query by using a probabilistic model of the objective. We’ll use a Gaussian process (GP) model, built using GPflow. The GPflow models cannot be used directly in our Bayesian optimization routines, so we build a GPflow’s <code class="docutils literal notranslate"><span class="pre">GPR</span></code> model and pass it to the <code class="docutils literal notranslate"><span class="pre">GaussianProcessRegression</span></code> wrapper.</p>
<p>Here as the first example, we model the objective function using the original data, without performing any data transformation. In the next example we will model it using normalised data. We also put priors on the parameters of our GP model’s kernel in order to stabilize model fitting. We found the priors below to be highly effective for objective functions defined over the unit hypercube and with an output normalised to have zero mean and unit variance. Since the non-normalised data from the
original objective function comes with different scaling, we rescale the priors based on approximate standard deviation of inputs and outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_gp_model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">x_std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">y_std</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">query_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">empirical_variance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_variance</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">observations</span><span class="p">)</span>

    <span class="n">prior_lengthscales</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span> <span class="o">*</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span> <span class="o">*</span> <span class="n">dim</span>
    <span class="n">prior_scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">x_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x_std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">y_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y_std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">kernel</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern52</span><span class="p">(</span>
        <span class="n">variance</span><span class="o">=</span><span class="n">empirical_variance</span><span class="p">,</span>
        <span class="n">lengthscales</span><span class="o">=</span><span class="n">prior_lengthscales</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">kernel</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_std</span><span class="p">),</span> <span class="n">prior_scale</span>
    <span class="p">)</span>
    <span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span><span class="p">),</span> <span class="n">prior_scale</span>
    <span class="p">)</span>
    <span class="n">gpr</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">(</span>
        <span class="n">data</span><span class="o">.</span><span class="n">astuple</span><span class="p">(),</span>
        <span class="n">kernel</span><span class="p">,</span>
        <span class="n">mean_function</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">mean_functions</span><span class="o">.</span><span class="n">Constant</span><span class="p">(),</span>
        <span class="n">noise_variance</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">gpflow</span><span class="o">.</span><span class="n">set_trainable</span><span class="p">(</span><span class="n">gpr</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">GaussianProcessRegression</span><span class="p">(</span><span class="n">gpr</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">build_gp_model</span><span class="p">(</span><span class="n">initial_data</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Run-the-optimization-loop">
<h2>Run the optimization loop<a class="headerlink" href="#Run-the-optimization-loop" title="Permalink to this headline">#</a></h2>
<p>We can now run the Bayesian optimization loop by defining a <code class="docutils literal notranslate"><span class="pre">BayesianOptimizer</span></code> and calling its <code class="docutils literal notranslate"><span class="pre">optimize</span></code> method.</p>
<p>The optimizer uses an acquisition rule to choose where in the search space to try on each optimization step. We’ll be using Expected improvement acquisition function - it is used by default, so no need to specify it.</p>
<p>We’ll run the optimizer for 100 steps. Note: this may take a while!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">bo</span> <span class="o">=</span> <span class="n">trieste</span><span class="o">.</span><span class="n">bayesian_optimizer</span><span class="o">.</span><span class="n">BayesianOptimizer</span><span class="p">(</span><span class="n">observer</span><span class="p">,</span> <span class="n">search_space</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">bo</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">initial_data</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">try_get_final_dataset</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Optimization completed without errors
</pre></div></div>
</div>
</div>
<div class="section" id="Explore-the-results">
<h2>Explore the results<a class="headerlink" href="#Explore-the-results" title="Permalink to this headline">#</a></h2>
<p>We can now get the best point found by the optimizer. Note this isn’t necessarily the point that was last evaluated. We will also plot regret for each optimization step.</p>
<p>We can see that the optimization did not get close to the global optimum of -210.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">query_points</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">query_points</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">observations</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">arg_min_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;query point: </span><span class="si">{</span><span class="n">query_points</span><span class="p">[</span><span class="n">arg_min_idx</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;observation: </span><span class="si">{</span><span class="n">observations</span><span class="p">[</span><span class="n">arg_min_idx</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
query point: [13.16241501 15.14978608 39.59754825 33.25901084 11.88421116 41.94497499
 26.68305277 -0.09315358 42.47048934 66.57413937]
observation: [4403.86390156]
</pre></div></div>
</div>
<p>We can plot regret for each optimization step to illustrate the performance more completely.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_regret_with_min</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">observations</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">observations</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">arg_min_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

    <span class="n">suboptimality</span> <span class="o">=</span> <span class="n">observations</span> <span class="o">-</span> <span class="n">F_MINIMUM</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">plot_regret</span><span class="p">(</span>
        <span class="n">suboptimality</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">num_init</span><span class="o">=</span><span class="n">num_initial_points</span><span class="p">,</span> <span class="n">idx_best</span><span class="o">=</span><span class="n">arg_min_idx</span>
    <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Regret&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;# evaluations&quot;</span><span class="p">)</span>


<span class="n">plot_regret_with_min</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_data_transformation_13_0.png" src="../_images/notebooks_data_transformation_13_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="Data-transformation-with-the-help-of-Ask-Tell-interface">
<h1>Data transformation with the help of Ask-Tell interface<a class="headerlink" href="#Data-transformation-with-the-help-of-Ask-Tell-interface" title="Permalink to this headline">#</a></h1>
<p>We will now show how data normalization can improve results achieved by Bayesian optimization.</p>
<p>We first write a simple function for doing the standardisation of the data, that is, we scale the data to have a zero mean and a variance equal to 1. We also return the mean and standard deviation parameters as we will use them to transform new points.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normalise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">std</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_variance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>
</pre></div>
</div>
</div>
<p>Note that we also need to modify the search space, from the original <span class="math notranslate nohighlight">\([-100, 100]\)</span> for all 10 dimensions to the normalised space. For illustration, <span class="math notranslate nohighlight">\([-1,1]\)</span> will suffice here.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">search_space</span> <span class="o">=</span> <span class="n">Box</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
<p>Next we have to define our own Bayesian optimization loop where Ask-Tell optimizer performs optimisation, and we take care of data transformation and model fitting.</p>
<p>We are using a simple approach whereby we normalize the initial data and use estimated mean and standard deviation from the initial normalization for transforming the new points that the Bayesian optimization loop adds to the dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_sta</span><span class="p">,</span> <span class="n">x_mean</span><span class="p">,</span> <span class="n">x_std</span> <span class="o">=</span> <span class="n">normalise</span><span class="p">(</span><span class="n">initial_data</span><span class="o">.</span><span class="n">query_points</span><span class="p">)</span>
<span class="n">y_sta</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">normalise</span><span class="p">(</span><span class="n">initial_data</span><span class="o">.</span><span class="n">observations</span><span class="p">)</span>
<span class="n">normalised_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">query_points</span><span class="o">=</span><span class="n">x_sta</span><span class="p">,</span> <span class="n">observations</span><span class="o">=</span><span class="n">y_sta</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">initial_data</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">build_gp_model</span><span class="p">(</span><span class="n">normalised_data</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">normalised_data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">normalised_data</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">normalised_data</span><span class="p">)</span>

    <span class="c1"># Asking for a new point to observe</span>
    <span class="n">ask_tell</span> <span class="o">=</span> <span class="n">AskTellOptimizer</span><span class="p">(</span><span class="n">search_space</span><span class="p">,</span> <span class="n">normalised_data</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">query_point</span> <span class="o">=</span> <span class="n">ask_tell</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>

    <span class="c1"># Transforming the query point back to the non-normalised space</span>
    <span class="n">query_point</span> <span class="o">=</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">query_point</span> <span class="o">+</span> <span class="n">x_mean</span>

    <span class="c1"># Evaluating the function at the new query point</span>
    <span class="n">new_data_point</span> <span class="o">=</span> <span class="n">observer</span><span class="p">(</span><span class="n">query_point</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span> <span class="o">+</span> <span class="n">new_data_point</span>

    <span class="c1"># Normalize the dataset with the new query point and observation</span>
    <span class="n">x_sta</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">normalise</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">query_points</span><span class="p">,</span> <span class="n">x_mean</span><span class="p">,</span> <span class="n">x_std</span><span class="p">)</span>
    <span class="n">y_sta</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">normalise</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">observations</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span><span class="p">)</span>
    <span class="n">normalised_data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">query_points</span><span class="o">=</span><span class="n">x_sta</span><span class="p">,</span> <span class="n">observations</span><span class="o">=</span><span class="n">y_sta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We inspect again the best point found by the optimizer and plot regret for each optimization step.</p>
<p>We can see that the optimization now gets almost to the global optimum of -210.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">query_points</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">query_points</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">observations</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">arg_min_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">plot_regret_with_min</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;query point: </span><span class="si">{</span><span class="n">query_points</span><span class="p">[</span><span class="n">arg_min_idx</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;observation: </span><span class="si">{</span><span class="n">observations</span><span class="p">[</span><span class="n">arg_min_idx</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
query point: [ 9.3623378  16.86357781 23.51415973 27.6250936  29.94412811 29.55239758
 27.51155394 23.17627839 16.33283705  9.51511639]
observation: [-208.09772932]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_data_transformation_21_1.png" src="../_images/notebooks_data_transformation_21_1.png" />
</div>
</div>
<div class="section" id="LICENSE">
<h2>LICENSE<a class="headerlink" href="#LICENSE" title="Permalink to this headline">#</a></h2>
<p><a class="reference external" href="https://github.com/secondmind-labs/trieste/blob/develop/LICENSE">Apache License 2.0</a></p>
</div>
</div>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright Copyright 2020 The Trieste Contributors

Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>