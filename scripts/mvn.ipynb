{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2373,
   "id": "90e51412-dad5-4e56-a892-6afa1260fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "base_dir = \"/\".join(os.getcwd().split(\"/\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2374,
   "id": "18fe164e-ca46-4280-a3bb-024278cef2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_monte_carlo_cdf(\n",
    "        mean: tf.Tensor,\n",
    "        cov: tf.Tensor,\n",
    "        lower: tf.Tensor,\n",
    "        upper: tf.Tensor,\n",
    "        num_samples: int,\n",
    "    ):\n",
    "    \n",
    "    normal = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "        loc=mean,\n",
    "        covariance_matrix=cov,\n",
    "    )\n",
    "    \n",
    "    samples = normal.sample(sample_shape=[num_samples])\n",
    "    \n",
    "    upper = tf.tile(upper[None, :], [num_samples, 1])\n",
    "    lower = tf.tile(lower[None, :], [num_samples, 1])\n",
    "    \n",
    "    ge = tf.cast(tf.math.greater_equal(samples, lower), dtype=tf.float32)\n",
    "    ge = tf.reduce_prod(ge, axis=-1)\n",
    "    \n",
    "    le = tf.cast(tf.math.less_equal(samples, upper), dtype=tf.float32)\n",
    "    le = tf.reduce_prod(le, axis=-1)\n",
    "    \n",
    "    indicator = tf.reduce_prod([ge, le], axis=0)\n",
    "    \n",
    "    return indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2463,
   "id": "ae0daf3d-9909-4708-8f33-35eab92a1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_add(tensor: tf.Tensor, index: List[int], update: tf.Tensor):\n",
    "    \n",
    "    index = tf.convert_to_tensor([index])\n",
    "    update = tf.convert_to_tensor([update])\n",
    "    \n",
    "    index = tf.convert_to_tensor(index)\n",
    "    updated = tf.tensor_scatter_nd_add(\n",
    "        tensor=tensor,\n",
    "        indices=index,\n",
    "        updates=update,\n",
    "    )\n",
    "    \n",
    "    return updated\n",
    "\n",
    "\n",
    "def vector_dot(a: tf.Tensor, b: tf.Tensor):\n",
    "    return tf.reduce_sum(a*b)\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def single_sample_cdf(\n",
    "        mean: tf.Tensor,\n",
    "        cov_chol: tf.Tensor,\n",
    "        lower: tf.Tensor,\n",
    "        upper: tf.Tensor,\n",
    "        samples: tf.Tensor,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "    \n",
    "    # Identify data type to use for all calculations\n",
    "    dtype = mean.dtype\n",
    "    \n",
    "    # Dimension of the integral\n",
    "    Q = mean.shape[-1]\n",
    "    \n",
    "    # Rename samples, limits and covariance cholesky for brevity\n",
    "    w = samples\n",
    "    a = lower\n",
    "    b = upper\n",
    "    C = cov_chol\n",
    "    \n",
    "    # Initialise transformation variables\n",
    "    d = tf.zeros_like(mean)\n",
    "    e = tf.zeros_like(mean)\n",
    "    f = tf.zeros_like(mean)\n",
    "    y = tf.zeros_like(mean)\n",
    "    \n",
    "    # Initialise standard normal for computing CDFs\n",
    "    normal = tfp.distributions.Normal(\n",
    "        loc=tf.zeros(shape=(), dtype=dtype),\n",
    "        scale=tf.ones(shape=(), dtype=dtype),\n",
    "    )\n",
    "    Phi = lambda x: normal.cdf(x)\n",
    "    iPhi = lambda x: normal.quantile(x)\n",
    "    \n",
    "    # Compute transformation variables at the first step\n",
    "    d = update_add(d, [0], Phi(a[0] / C[0, 0]))\n",
    "    e = update_add(e, [0], Phi(b[0] / C[0, 0]))\n",
    "    f = update_add(f, [0], e[0] - d[0])\n",
    "\n",
    "    for i in tf.range(1, Q):\n",
    "        \n",
    "        # Update y[i-1]\n",
    "        y = update_add(y, [i-1], iPhi(d[i-1] + w[i-1] * (e[i-1] - d[i-1])))\n",
    "        \n",
    "        # Update d[i-1] and e[i-1]\n",
    "        d = update_add(d, [i], Phi((a[i] - vector_dot(C[i, :i], y[:i])) / C[i, i]))\n",
    "        e = update_add(e, [i], Phi((b[i] - vector_dot(C[i, :i], y[:i])) / C[i, i]))\n",
    "        f = update_add(f, [i], (e[i] - d[i]) * f[i-1])\n",
    "        \n",
    "    return f[-1]\n",
    "\n",
    "\n",
    "def mc_mvn_cdf(\n",
    "        mean: tf.Tensor,\n",
    "        cov: tf.Tensor,\n",
    "        lower: tf.Tensor,\n",
    "        upper: tf.Tensor,\n",
    "        num_samples: int,\n",
    "    ):\n",
    "    \n",
    "    samples = tfd.MultivariateNormalFullCovariance(\n",
    "        loc=mean,\n",
    "        covariance_matrix=cov,\n",
    "    ).sample(sample_shape=[num_samples])\n",
    "    \n",
    "    lt = tf.reduce_all(tf.math.less(lower, samples), axis=1)\n",
    "    gt = tf.reduce_all(tf.math.less(samples, upper), axis=1)\n",
    "    \n",
    "    return tf.cast(tf.math.logical_and(lt, gt), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2474,
   "id": "777f1b3b-aac9-4635-8741-11197a9e86f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.02198314300289297>"
      ]
     },
     "execution_count": 2474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Set default data type\n",
    "dtype = tf.float64\n",
    "\n",
    "# Number of samples and dimension of Gaussian\n",
    "S = 100\n",
    "Q = 10\n",
    "\n",
    "# Set up the mean and covariance\n",
    "mean = tf.zeros(shape=(Q,), dtype=dtype)\n",
    "rand = tf.random.uniform((Q, Q), dtype=dtype) / Q**0.5\n",
    "cov = 1e-1 * tf.matmul(rand, rand, transpose_b=True) + tf.eye(Q, dtype=dtype)\n",
    "\n",
    "# Set up lower and upper integration limits\n",
    "upper = tf.random.uniform((Q,), dtype=dtype)\n",
    "lower = float(\"-inf\") * tf.ones_like(upper)\n",
    "\n",
    "# Equally well, you can use Sobol sequences by replacing the line above with\n",
    "samples = tf.math.sobol_sample(dim=Q, num_results=S, dtype=dtype)\n",
    "\n",
    "_single_sample_cdf = lambda x: single_sample_cdf(mean, tf.linalg.cholesky(cov), lower, upper, x)\n",
    "_single_sample_cdf(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2475,
   "id": "4bf6a377-4978-45bf-b10e-a11049ad80d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive CDF: 0.023383999 +/- 0.000302239\n",
      "Genz  CDF: 0.023169078 +/- 0.000505986\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw samples to use within the MC estiamate\n",
    "num_samples = 1000000\n",
    "naive_cdf = mc_mvn_cdf(mean=mean, cov=cov, lower=lower, upper=upper, num_samples=num_samples)\n",
    "\n",
    "samples = tf.math.sobol_sample(dim=Q, num_results=S, dtype=dtype)\n",
    "cdf = tf.map_fn(_single_sample_cdf, samples)\n",
    "\n",
    "print(f\"Naive CDF: {tf.reduce_mean(naive_cdf):.9f} +/- {2*tf.math.reduce_std(naive_cdf)/num_samples**0.5:.9f}\")\n",
    "print(f\"Genz  CDF: {tf.reduce_mean(cdf):.9f} +/- {2*tf.math.reduce_std(cdf)/S**0.5:.9f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.hist(cdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2476,
   "id": "93150eb9-d8ee-47fd-a9f2-f49d46496e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@tf.function\n",
    "def mvn_cdf(\n",
    "        mean: tf.Tensor,\n",
    "        cov: tf.Tensor,\n",
    "        lower: tf.Tensor,\n",
    "        upper: tf.Tensor,\n",
    "        num_sobol: int = 10,\n",
    "        verbose=False,\n",
    "    ):\n",
    "    \n",
    "    B, Q = mean.shape\n",
    "    dtype = mean.dtype\n",
    "    \n",
    "    chol = tf.linalg.cholesky(cov)\n",
    "    \n",
    "    samples = tf.math.sobol_sample(\n",
    "        dim=Q,\n",
    "        num_results=num_sobol,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    \n",
    "    cdf = lambda args: tf.reduce_mean(tf.map_fn(partial(single_sample_cdf, *args, verbose=verbose), samples))\n",
    "    cdf = tf.map_fn(cdf, [mean, chol, lower, upper], fn_output_signature=dtype)\n",
    "    \n",
    "    return cdf\n",
    "\n",
    "\n",
    "def compute_bm(\n",
    "        mean: tf.Tensor,\n",
    "        threshold: tf.Tensor,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        mean: tf.Tensor, shape (B, Q)\n",
    "        threshold: tf.Tensor, shape (B,)\n",
    "        \n",
    "    Returns:\n",
    "        b: tf.Tensor, shape (B, Q, Q), b[B, K, Q]\n",
    "        m: tf.Tensor, shape (B, Q, Q), m[B, K, Q]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack tensor shape and data type\n",
    "    B, Q = mean.shape\n",
    "    dtype = mean.dtype\n",
    "    \n",
    "    # Compute b tensor\n",
    "    threshold = tf.tile(threshold[:, None], (1, Q))\n",
    "    threshold = tf.linalg.diag(threshold) # (B, Q, Q)\n",
    "    \n",
    "    b = tf.zeros(shape=(B, Q, Q), dtype=dtype)\n",
    "    b = b - threshold\n",
    "    \n",
    "    # Compute m tensor\n",
    "    m = mean[:, None, :] - mean[:, :, None]  # (B, Q, Q)\n",
    "    m = m - tf.linalg.diag(mean)  # (B, Q, Q)\n",
    "    \n",
    "    return b, m\n",
    "\n",
    "\n",
    "def delta(idx: int, dim: int, B: int, transpose: bool, dtype: tf.DType):\n",
    "    \n",
    "    o1 = tf.ones(shape=(B, idx, dim), dtype=dtype)\n",
    "    z1 = tf.zeros(shape=(B, 1, dim), dtype=dtype)\n",
    "    o2 = tf.ones(shape=(B, dim-idx-1, dim), dtype=dtype)\n",
    "    \n",
    "    delta = tf.concat([o1, z1, o2], axis=1)\n",
    "    delta = tf.transpose(delta, perm=[0, 2, 1]) if transpose else delta\n",
    "    \n",
    "    return delta\n",
    "    \n",
    "\n",
    "def compute_Sigma(covariance: tf.Tensor):\n",
    "    \n",
    "    B, Q, _ = covariance.shape\n",
    "    dtype = covariance.dtype\n",
    "    \n",
    "    Sigma = tf.zeros(shape=(B, Q, Q, Q))\n",
    "    \n",
    "    def compute_single_slice(q):\n",
    "        \n",
    "        diq = delta(q, Q, B, transpose=False, dtype=dtype)\n",
    "        dqj = delta(q, Q, B, transpose=True, dtype=dtype)\n",
    "        \n",
    "        Sigma_ij = covariance[:, :, :]\n",
    "        Sigma_iq = covariance[:, :, q:q+1]\n",
    "        Sigma_qj = covariance[:, q:q+1, :]\n",
    "        Sigma_qq = covariance[:, q:q+1, q:q+1]\n",
    "        \n",
    "        cov = Sigma_ij * diq * dqj - Sigma_iq * diq - Sigma_qj * dqj + Sigma_qq\n",
    "        \n",
    "        return cov\n",
    "    \n",
    "    Sigma = tf.map_fn(\n",
    "        compute_single_slice,\n",
    "        tf.range(Q),\n",
    "        fn_output_signature=dtype,\n",
    "    )\n",
    "    \n",
    "    Sigma = tf.transpose(Sigma, perm=[1, 0, 2, 3])\n",
    "        \n",
    "    return Sigma\n",
    "\n",
    "\n",
    "def compute_p(\n",
    "        m_reshaped: tf.Tensor,\n",
    "        b_reshaped: tf.Tensor,\n",
    "        Sigma_reshaped: tf.Tensor,\n",
    "    ):\n",
    "    \n",
    "    # Unpack dtype and mean shape\n",
    "    dtype = m_reshaped.dtype\n",
    "    BQ, Q = m_reshaped.shape # (B*Q, Q)\n",
    "    \n",
    "    # Compute mean, covariance, lower and upper bounds for p mvn normal cdf\n",
    "    p_cdf_mean = tf.zeros(shape=(BQ, Q), dtype=dtype)  # (B*Q, Q)\n",
    "    p_cdf_cov = Sigma_reshaped # (B*Q, Q, Q)\n",
    "    \n",
    "    p_cdf_upper = b_reshaped - m_reshaped  # (B*Q, Q)\n",
    "    p_cdf_lower = float(\"-inf\") * tf.ones_like(p_cdf_upper)  # (B*Q, Q)\n",
    "    \n",
    "    # Compute MVN CDF\n",
    "    p = mvn_cdf(\n",
    "        mean=p_cdf_mean,\n",
    "        cov=p_cdf_cov,\n",
    "        lower=p_cdf_lower,\n",
    "        upper=p_cdf_upper,\n",
    "    )  # (B*Q,)\n",
    "    \n",
    "    p = tf.reshape(p, shape=(B, Q))  # (B, Q)\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "def compute_ci(\n",
    "        m_reshaped: tf.Tensor,\n",
    "        b_reshaped: tf.Tensor,\n",
    "        Sigma_reshaped: tf.Tensor,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        m_reshaped: tf.Tensor, shape (B*Q, Q)\n",
    "        b_reshaped: tf.Tensor, shape (B*Q, Q)\n",
    "        Sigma_reshaped: tf.Tensor, shape (B*Q, Q, Q)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack tensor shape and data type\n",
    "    BQ, Q = m_reshaped.shape\n",
    "    dtype = m_reshaped.dtype\n",
    "    \n",
    "    # Compute difference between b and m tensors\n",
    "    diff = b_reshaped - m_reshaped # (B*Q, Q)\n",
    "    \n",
    "    # Compute ci, including the ith entry, which we want to remove\n",
    "    cov_ratio = Sigma_reshaped / tf.linalg.diag_part(Sigma_reshaped)[:, :, None] # (B*Q, Q, Q)\n",
    "    ci = diff[:, None, :] - diff[:, :, None] * cov_ratio # (B*Q, Q, Q)\n",
    "    \n",
    "    # Remove the ith entry by masking ci with a boolean mask with False across\n",
    "    # the diagonal and True in the off-diagonal terms\n",
    "    mask = tf.math.logical_not(tf.cast(tf.eye(Q, dtype=tf.int32), dtype=tf.bool))\n",
    "    mask = tf.tile(mask[None, :, :], (ci.shape[0], 1, 1))\n",
    "    \n",
    "    ci = tf.ragged.boolean_mask(ci, mask).to_tensor()\n",
    "    \n",
    "    return ci\n",
    "\n",
    "\n",
    "def compute_Sigmai_matrix(Sigma_reshaped):\n",
    "    \"\"\"\n",
    "    Sigma_reshaped: tf.Tensor, shape (B*Q, Q, Q)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack tensor shape\n",
    "    BQ, Q, _ = Sigma_reshaped.shape\n",
    "    \n",
    "    Sigma_uv = tf.tile(Sigma_reshaped[:, None, :, :], (1, Q, 1, 1))\n",
    "    Sigma_iu = tf.tile(Sigma_reshaped[:, :, :, None], (1, 1, 1, Q))\n",
    "    Sigma_iv = tf.tile(Sigma_reshaped[:, :, None, :], (1, 1, Q, 1))\n",
    "    Sigma_ii = tf.linalg.diag_part(Sigma_reshaped)[:, :, None, None]\n",
    "    \n",
    "    Sigmai_whole = Sigma_uv - Sigma_iu * Sigma_iv / Sigma_ii\n",
    "    \n",
    "    def create_blocks(q):\n",
    "        \n",
    "        block1 = tf.concat(\n",
    "            [\n",
    "                Sigmai_whole[:, q, :q, :q],\n",
    "                Sigmai_whole[:, q, q+1:, :q],\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        \n",
    "        block2 = tf.concat(\n",
    "            [\n",
    "                Sigmai_whole[:, q, :q, q+1:],\n",
    "                Sigmai_whole[:, q, q+1:, q+1:],\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        \n",
    "        Sigmai_block = tf.concat([block1, block2], axis=2)\n",
    "        \n",
    "        return Sigmai_block\n",
    "    \n",
    "    Sigmai = tf.map_fn(\n",
    "        create_blocks,\n",
    "        tf.range(Q),\n",
    "        fn_output_signature=Sigmai_whole.dtype,\n",
    "    )\n",
    "    Sigmai = tf.transpose(Sigmai, perm=[1, 0, 2, 3])\n",
    "    \n",
    "    return Sigmai\n",
    "\n",
    "\n",
    "def compute_Phi(\n",
    "        ci: tf.Tensor,\n",
    "        Sigmai: tf.Tensor,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        ci: tf.Tensor, shape (B*Q, Q, Q-1)\n",
    "        Sigmai: tf.Tensor, shape (B*Q, Q, Q, Q-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack tensor shape and data type\n",
    "    BQ, Q, _, _ = Sigmai.shape\n",
    "    dtype = Sigmai.dtype\n",
    "\n",
    "    ci_reshaped = tf.reshape(ci, (BQ*Q, Q-1))\n",
    "    Sigmai_reshaped = tf.reshape(Sigmai, (BQ*Q, Q-1, Q-1))\n",
    "    \n",
    "    # Compute mean, covariance, lower and upper bounds for Phi mvn normal cdf\n",
    "    Phi_cdf_mean = tf.zeros(shape=(BQ*Q, Q-1), dtype=dtype)  # (B*Q*Q, Q)\n",
    "    Phi_cdf_cov = Sigmai_reshaped  # (B*Q*Q, Q-1, Q-1)\n",
    "    \n",
    "    Phi_cdf_upper = ci_reshaped  # (B*Q, Q-1)\n",
    "    Phi_cdf_lower = float(\"-inf\") * tf.ones_like(Phi_cdf_upper)  # (B*Q*Q, Q-1)\n",
    "    \n",
    "    # Compute multivariate cdfs\n",
    "    mvn_cdfs = mvn_cdf(\n",
    "        mean=Phi_cdf_mean,\n",
    "        cov=Phi_cdf_cov,\n",
    "        lower=Phi_cdf_lower,\n",
    "        upper=Phi_cdf_upper,\n",
    "        verbose=True,\n",
    "    )\n",
    "    mvn_cdfs = tf.reshape(mvn_cdfs, (B, Q, Q))  # (B, Q, Q)\n",
    "    \n",
    "    return mvn_cdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2477,
   "id": "ce4f2d16-8042-4113-803f-cfd5d809ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def expected_improvement(\n",
    "        mean: tf.Tensor,\n",
    "        covariance: tf.Tensor,\n",
    "        threshold: tf.Tensor,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        mean: tf.Tensor, shape (B, Q)\n",
    "        covariance: tf.Tensor, shape (B, Q, Q)\n",
    "        threshold: tf.Tensor, shape (B,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack dtype and mean shape\n",
    "    dtype = mean.dtype\n",
    "    B, Q = mean.shape\n",
    "    \n",
    "    # Compute b and m tensors\n",
    "    b, m = compute_bm(mean=mean, threshold=threshold) # (B, Q, Q), (B, Q, Q)\n",
    "        \n",
    "    # Compute Sigma\n",
    "    Sigma = compute_Sigma(covariance=covariance) # (B, Q, Q, Q)\n",
    "    \n",
    "    # Reshape all tensors, for batching\n",
    "    b_reshaped = tf.reshape(b, (B*Q, Q))\n",
    "    m_reshaped = tf.reshape(m, (B*Q, Q))\n",
    "    Sigma_reshaped = tf.reshape(Sigma, (B*Q, Q, Q))\n",
    "    \n",
    "    # Compute p tensor\n",
    "    p = compute_p(\n",
    "        m_reshaped=m_reshaped,\n",
    "        b_reshaped=b_reshaped,\n",
    "        Sigma_reshaped=Sigma_reshaped,\n",
    "    )\n",
    "        \n",
    "    # Compute ci\n",
    "    ci = compute_ci(\n",
    "        m_reshaped=m_reshaped,\n",
    "        b_reshaped=b_reshaped,\n",
    "        Sigma_reshaped=Sigma_reshaped,\n",
    "    ) # (B*Q, Q, Q-1)\n",
    "        \n",
    "    # Compute Sigma_i\n",
    "    Sigmai = compute_Sigmai_matrix(\n",
    "        Sigma_reshaped=Sigma_reshaped,\n",
    "    ) # (B*Q, Q, Q-1, Q-1)\n",
    "    \n",
    "    # Compute Q-1 multivariate CDFs\n",
    "    Phi_mvn_cdfs = compute_Phi(\n",
    "        ci=ci,\n",
    "        Sigmai=Sigmai,\n",
    "    )\n",
    "        \n",
    "    # Compute univariate cdfs\n",
    "    S_diag = tf.linalg.diag_part(Sigma)\n",
    "    normal = tfp.distributions.Normal(loc=m, scale=S_diag**0.5)\n",
    "    uvn_cdfs = tf.math.exp(normal.log_prob(b))  # (B, Q, Q)\n",
    "    \n",
    "    Sigma_diag = tf.linalg.diag_part(\n",
    "        tf.transpose(Sigma, perm=[0, 2, 1, 3])\n",
    "    )\n",
    "    Sigma_diag = tf.transpose(Sigma_diag, perm=[0, 2, 1])\n",
    "    \n",
    "    T = tf.tile(threshold[:, None], (1, Q))\n",
    "    \n",
    "    mean_T_term = (mean - T) * p\n",
    "    \n",
    "    sum_term = tf.reduce_sum(\n",
    "        Sigma_diag * uvn_cdfs * Phi_mvn_cdfs,\n",
    "        axis=2,\n",
    "    )\n",
    "    \n",
    "    qEI = tf.reduce_sum(mean_T_term + sum_term, axis=1)\n",
    "    \n",
    "    return qEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2480,
   "id": "956ae45e-da3e-407a-876e-784f2984e763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.70017961, 0.49411829, 0.82302765, 0.84141032])>"
      ]
     },
     "execution_count": 2480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "B = 4\n",
    "Q = 20\n",
    "\n",
    "# mean = tf.random.uniform(shape=(B, Q), dtype=dtype)\n",
    "mean = tf.zeros(shape=(B, Q), dtype=dtype)\n",
    "rand = tf.random.uniform((B, Q, Q), dtype=dtype) / Q**0.5\n",
    "covariance = 1e-1 * tf.matmul(rand, rand, transpose_b=True) + tf.eye(Q, dtype=dtype)[None, ...]\n",
    "\n",
    "threshold = tf.random.uniform((B,), dtype=dtype)\n",
    "\n",
    "expected_improvement(mean=mean, covariance=covariance, threshold=threshold, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2481,
   "id": "d7ecbee2-d164-47f7-93ec-dd46c4fb3096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 ms ± 70.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = expected_improvement(mean=mean, covariance=covariance, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2460,
   "id": "c74c8088-d3c8-4ff3-ac64-b16af68ec70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcei(\n",
    "        mean: tf.Tensor,\n",
    "        covariance: tf.Tensor,\n",
    "        threshold: tf.Tensor,\n",
    "        num_samples: int = 1000000,\n",
    "    ):\n",
    "    \n",
    "    mvn = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "        loc=mean,\n",
    "        covariance_matrix=covariance,\n",
    "    )\n",
    "    \n",
    "    samples = mvn.sample(sample_shape=[num_samples])\n",
    "    \n",
    "    tiled_threshold = tf.tile(\n",
    "        threshold[None, :, None],\n",
    "        (num_samples, 1, 1),\n",
    "    )\n",
    "    \n",
    "    print(f\"{samples.shape=} {tiled_threshold.shape=}\")\n",
    "    \n",
    "    samples_and_thresholds = tf.concat(\n",
    "        [samples, tiled_threshold], axis=-1\n",
    "    )\n",
    "    maxima = tf.reduce_max(samples_and_thresholds, axis=-1)\n",
    "    improvements = maxima - threshold[None, :]\n",
    "    \n",
    "    if tf.reduce_any(tf.less(improvements, tf.zeros_like(improvements))):\n",
    "        raise Exception\n",
    "    \n",
    "    return tf.reduce_mean(improvements, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2461,
   "id": "ace5d6cb-a079-4729-b2ef-5b68be21fdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples.shape=TensorShape([1000000, 4, 10]) tiled_threshold.shape=TensorShape([1000000, 4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float64, numpy=array([1.10449005, 0.66299733, 1.38576022, 1.43001959])>"
      ]
     },
     "execution_count": 2461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcei(mean=mean, covariance=covariance, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fe5c05-8489-4e90-95ee-5bbaf011443c",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "- Write down qEI derivation following Ginsbourger.\n",
    "- Implement qEI without batching using for-loops.\n",
    "- Look at values using above implentation, with special values for mean, covariance and threshold, for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5df6fd-dead-4daf-98a4-ca26edf0ae09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-trieste",
   "language": "python",
   "name": "venv-trieste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
