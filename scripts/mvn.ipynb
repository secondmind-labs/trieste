{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2373,
   "id": "90e51412-dad5-4e56-a892-6afa1260fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "base_dir = \"/\".join(os.getcwd().split(\"/\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2374,
   "id": "18fe164e-ca46-4280-a3bb-024278cef2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_monte_carlo_cdf(\n",
    "        mean: tf.Tensor,\n",
    "        cov: tf.Tensor,\n",
    "        lower: tf.Tensor,\n",
    "        upper: tf.Tensor,\n",
    "        num_samples: int,\n",
    "    ):\n",
    "    \n",
    "    normal = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "        loc=mean,\n",
    "        covariance_matrix=cov,\n",
    "    )\n",
    "    \n",
    "    samples = normal.sample(sample_shape=[num_samples])\n",
    "    \n",
    "    upper = tf.tile(upper[None, :], [num_samples, 1])\n",
    "    lower = tf.tile(lower[None, :], [num_samples, 1])\n",
    "    \n",
    "    ge = tf.cast(tf.math.greater_equal(samples, lower), dtype=tf.float32)\n",
    "    ge = tf.reduce_prod(ge, axis=-1)\n",
    "    \n",
    "    le = tf.cast(tf.math.less_equal(samples, upper), dtype=tf.float32)\n",
    "    le = tf.reduce_prod(le, axis=-1)\n",
    "    \n",
    "    indicator = tf.reduce_prod([ge, le], axis=0)\n",
    "    \n",
    "    return indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2375,
   "id": "ae0daf3d-9909-4708-8f33-35eab92a1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_add(\n",
    "        tensor: tf.Tensor,\n",
    "        index: List[int],\n",
    "        update: tf.Tensor,\n",
    "    ):\n",
    "    \n",
    "    index = tf.convert_to_tensor([index])\n",
    "    update = tf.convert_to_tensor([update])\n",
    "    \n",
    "    index = tf.convert_to_tensor(index)\n",
    "    updated = tf.tensor_scatter_nd_add(\n",
    "        tensor=tensor,\n",
    "        indices=index,\n",
    "        updates=update,\n",
    "    )\n",
    "    \n",
    "    return updated\n",
    "\n",
    "\n",
    "def vector_dot(\n",
    "        a: tf.Tensor,\n",
    "        b: tf.Tensor,\n",
    "    ):\n",
    "    \n",
    "    return tf.reduce_sum(a*b)\n",
    "\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def single_sample_cdf(\n",
    "        mean: tf.Tensor,\n",
    "        cov_chol: tf.Tensor,\n",
    "        lower: tf.Tensor,\n",
    "        upper: tf.Tensor,\n",
    "        samples: tf.Tensor,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "    \n",
    "    # Identify data type to use for all calculations\n",
    "    dtype = mean.dtype\n",
    "    \n",
    "    # Dimension of the integral\n",
    "    Q = mean.shape[-1]\n",
    "    \n",
    "    # Rename samples, limits and covariance cholesky for brevity\n",
    "    w = samples\n",
    "    a = lower\n",
    "    b = upper\n",
    "    C = cov_chol\n",
    "    \n",
    "    # Initialise transformation variables\n",
    "    d = tf.zeros_like(mean)\n",
    "    e = tf.zeros_like(mean)\n",
    "    f = tf.zeros_like(mean)\n",
    "    y = tf.zeros_like(mean)\n",
    "    \n",
    "    # Initialise standard normal for computing CDFs\n",
    "    normal = tfp.distributions.Normal(\n",
    "        loc=tf.zeros(shape=(), dtype=dtype),\n",
    "        scale=tf.ones(shape=(), dtype=dtype),\n",
    "    )\n",
    "    Phi = lambda x: normal.cdf(x)\n",
    "    iPhi = lambda x: normal.quantile(x)\n",
    "    \n",
    "    # Compute transformation variables at the first step\n",
    "    d = update_add(d, [0], Phi(a[0] / C[0, 0]))\n",
    "    e = update_add(e, [0], Phi(b[0] / C[0, 0]))\n",
    "    f = update_add(f, [0], e[0] - d[0])\n",
    "\n",
    "    for i in tf.range(1, Q):\n",
    "        \n",
    "        # Update y[i-1]\n",
    "        y = update_add(y, [i-1], iPhi(d[i-1] + w[i-1] * (e[i-1] - d[i-1])))\n",
    "        \n",
    "        # Update d[i-1] and e[i-1]\n",
    "        d = update_add(d, [i], Phi((a[i] - vector_dot(C[i, :i], y[:i])) / C[i, i]))\n",
    "        e = update_add(e, [i], Phi((b[i] - vector_dot(C[i, :i], y[:i])) / C[i, i]))\n",
    "        f = update_add(f, [i], (e[i] - d[i]) * f[i-1])\n",
    "        \n",
    "        # tf.print(y[i-1], d[i], e[i], f[i])\n",
    "        # input(\"\")\n",
    "        \n",
    "    return f[-1]\n",
    "\n",
    "\n",
    "def mc_mvn_cdf(\n",
    "        mean: tf.Tensor,\n",
    "        cov: tf.Tensor,\n",
    "        lower: tf.Tensor,\n",
    "        upper: tf.Tensor,\n",
    "        num_samples: int,\n",
    "    ):\n",
    "    \n",
    "    samples = tfd.MultivariateNormalFullCovariance(\n",
    "        loc=mean,\n",
    "        covariance_matrix=cov,\n",
    "    ).sample(sample_shape=[num_samples])\n",
    "    \n",
    "    lt = tf.reduce_all(tf.math.less(lower, samples), axis=1)\n",
    "    gt = tf.reduce_all(tf.math.less(samples, upper), axis=1)\n",
    "    \n",
    "    return tf.cast(tf.math.logical_and(lt, gt), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2376,
   "id": "777f1b3b-aac9-4635-8741-11197a9e86f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.4911282990024978e-05>"
      ]
     },
     "execution_count": 2376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Set default data type\n",
    "dtype = tf.float64\n",
    "\n",
    "# Number of samples and dimension of Gaussian\n",
    "S = 10\n",
    "Q = 10\n",
    "\n",
    "# Set up the mean and covariance\n",
    "mean = tf.zeros(shape=(Q,), dtype=dtype)\n",
    "rand = tf.random.uniform((Q, Q), dtype=dtype)\n",
    "cov = 0. * tf.matmul(rand, rand, transpose_b=True) + tf.eye(Q, dtype=dtype)\n",
    "\n",
    "# Set up lower and upper integration limits\n",
    "lower = - tf.random.uniform((Q,), dtype=dtype)\n",
    "upper = tf.random.uniform((Q,), dtype=dtype)\n",
    "\n",
    "# Draw samples to use within the MC estiamate\n",
    "samples = tf.random.uniform(shape=(S, Q), dtype=dtype)\n",
    "\n",
    "# Equally well, you can use Sobol sequences by replacing the line above with\n",
    "samples = tf.math.sobol_sample(dim=Q, num_results=S, dtype=dtype)\n",
    "\n",
    "_single_sample_cdf = lambda x: single_sample_cdf(mean, tf.linalg.cholesky(cov), lower, upper, x)\n",
    "_single_sample_cdf(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2377,
   "id": "4bf6a377-4978-45bf-b10e-a11049ad80d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive CDF: 0.000015000 +/- 0.000007746\n",
      "Genz  CDF: 0.000014911 +/- 0.000000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw samples to use within the MC estiamate\n",
    "num_samples = 1000000\n",
    "naive_cdf = mc_mvn_cdf(mean=mean, cov=cov, lower=lower, upper=upper, num_samples=num_samples)\n",
    "\n",
    "samples = tf.math.sobol_sample(dim=Q, num_results=S, dtype=dtype)\n",
    "cdf = tf.map_fn(_single_sample_cdf, samples)\n",
    "\n",
    "print(f\"Naive CDF: {tf.reduce_mean(naive_cdf):.9f} +/- {2*tf.math.reduce_std(naive_cdf)/num_samples**0.5:.9f}\")\n",
    "print(f\"Genz  CDF: {tf.reduce_mean(cdf):.9f} +/- {2*tf.math.reduce_std(cdf)/S**0.5:.9f}\")\n",
    "\n",
    "plt.hist(cdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2407,
   "id": "93150eb9-d8ee-47fd-a9f2-f49d46496e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@tf.function\n",
    "def mvn_cdf(\n",
    "        mean: tf.Tensor,\n",
    "        cov: tf.Tensor,\n",
    "        lower: tf.Tensor,\n",
    "        upper: tf.Tensor,\n",
    "        num_sobol: int = 500,\n",
    "        verbose=False,\n",
    "    ):\n",
    "    \n",
    "    B, Q = mean.shape\n",
    "    dtype = mean.dtype\n",
    "    \n",
    "    chol = tf.linalg.cholesky(cov)\n",
    "    \n",
    "    samples = tf.math.sobol_sample(\n",
    "        dim=Q,\n",
    "        num_results=num_sobol,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    \n",
    "    cdf = lambda args: tf.reduce_mean(tf.map_fn(partial(single_sample_cdf, *args, verbose=verbose), samples))\n",
    "    cdf = tf.map_fn(cdf, [mean, chol, lower, upper], fn_output_signature=dtype)\n",
    "    \n",
    "    return cdf\n",
    "\n",
    "\n",
    "def compute_bm(\n",
    "        mean: tf.Tensor,\n",
    "        threshold: tf.Tensor,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        mean: tf.Tensor, shape (B, Q)\n",
    "        threshold: tf.Tensor, shape (B,)\n",
    "        \n",
    "    Returns:\n",
    "        b: tf.Tensor, shape (B, Q, Q), b[B, K, Q]\n",
    "        m: tf.Tensor, shape (B, Q, Q), m[B, K, Q]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack tensor shape and data type\n",
    "    B, Q = mean.shape\n",
    "    dtype = mean.dtype\n",
    "    \n",
    "    # Compute b tensor\n",
    "    threshold = tf.tile(threshold[:, None], (1, Q))\n",
    "    threshold = tf.linalg.diag(threshold) # (B, Q, Q)\n",
    "    \n",
    "    b = tf.zeros(shape=(B, Q, Q), dtype=dtype)\n",
    "    b = b - threshold\n",
    "    \n",
    "    # Compute m tensor\n",
    "    m = mean[:, None, :] - mean[:, :, None]  # (B, Q, Q)\n",
    "    m = m - tf.linalg.diag(mean)  # (B, Q, Q)\n",
    "    \n",
    "    return b, m\n",
    "\n",
    "\n",
    "def delta(idx: int, dim: int, B: int, transpose: bool, dtype: tf.DType):\n",
    "    \n",
    "    o1 = tf.ones(shape=(B, idx, dim), dtype=dtype)\n",
    "    z1 = tf.zeros(shape=(B, 1, dim), dtype=dtype)\n",
    "    o2 = tf.ones(shape=(B, dim-idx-1, dim), dtype=dtype)\n",
    "    \n",
    "    delta = tf.concat([o1, z1, o2], axis=1)\n",
    "    delta = tf.transpose(delta, perm=[0, 2, 1]) if transpose else delta\n",
    "    \n",
    "    return delta\n",
    "    \n",
    "\n",
    "def compute_Sigma(covariance: tf.Tensor):\n",
    "    \n",
    "    B, Q, _ = covariance.shape\n",
    "    dtype = covariance.dtype\n",
    "    \n",
    "    Sigma = tf.zeros(shape=(B, Q, Q, Q))\n",
    "    \n",
    "    def compute_single_slice(q):\n",
    "        \n",
    "        diq = delta(q, Q, B, transpose=False, dtype=dtype)\n",
    "        dqj = delta(q, Q, B, transpose=True, dtype=dtype)\n",
    "        \n",
    "        Sigma_ij = covariance[:, :, :]\n",
    "        Sigma_iq = covariance[:, :, q:q+1]\n",
    "        Sigma_qj = covariance[:, q:q+1, :]\n",
    "        Sigma_qq = covariance[:, q:q+1, q:q+1]\n",
    "        \n",
    "        cov = Sigma_ij * diq * dqj - Sigma_iq * diq - Sigma_qj * dqj + Sigma_qq\n",
    "        \n",
    "        return cov\n",
    "    \n",
    "    Sigma = tf.map_fn(\n",
    "        compute_single_slice,\n",
    "        tf.range(Q),\n",
    "        fn_output_signature=dtype,\n",
    "    )\n",
    "    \n",
    "    Sigma = tf.transpose(Sigma, perm=[1, 0, 2, 3])\n",
    "        \n",
    "    return Sigma\n",
    "\n",
    "\n",
    "def compute_p(\n",
    "        m_reshaped: tf.Tensor,\n",
    "        b_reshaped: tf.Tensor,\n",
    "        Sigma_reshaped: tf.Tensor,\n",
    "    ):\n",
    "    \n",
    "    # Unpack dtype and mean shape\n",
    "    dtype = m_reshaped.dtype\n",
    "    BQ, Q = m_reshaped.shape # (B*Q, Q)\n",
    "    \n",
    "    # Compute mean, covariance, lower and upper bounds for p mvn normal cdf\n",
    "    p_cdf_mean = tf.zeros(shape=(BQ, Q), dtype=dtype)  # (B*Q, Q)\n",
    "    p_cdf_cov = Sigma_reshaped # (B*Q, Q, Q)\n",
    "    \n",
    "    p_cdf_upper = b_reshaped - m_reshaped  # (B*Q, Q)\n",
    "    p_cdf_lower = float(\"-inf\") * tf.ones_like(p_cdf_upper)  # (B*Q, Q)\n",
    "    \n",
    "    # Compute MVN CDF\n",
    "    p = mvn_cdf(\n",
    "        mean=p_cdf_mean,\n",
    "        cov=p_cdf_cov,\n",
    "        lower=p_cdf_lower,\n",
    "        upper=p_cdf_upper,\n",
    "    )  # (B*Q,)\n",
    "    \n",
    "    p = tf.reshape(p, shape=(B, Q))  # (B, Q)\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "def compute_ci(\n",
    "        m_reshaped: tf.Tensor,\n",
    "        b_reshaped: tf.Tensor,\n",
    "        Sigma_reshaped: tf.Tensor,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        m_reshaped: tf.Tensor, shape (B*Q, Q)\n",
    "        b_reshaped: tf.Tensor, shape (B*Q, Q)\n",
    "        Sigma_reshaped: tf.Tensor, shape (B*Q, Q, Q)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack tensor shape and data type\n",
    "    BQ, Q = m_reshaped.shape\n",
    "    dtype = m_reshaped.dtype\n",
    "    \n",
    "    # Compute difference between b and m tensors\n",
    "    diff = b_reshaped - m_reshaped # (B*Q, Q)\n",
    "    \n",
    "    # Compute ci, including the ith entry, which we want to remove\n",
    "    cov_ratio = Sigma_reshaped / tf.linalg.diag_part(Sigma_reshaped)[:, :, None] # (B*Q, Q, Q)\n",
    "    ci = diff[:, None, :] - diff[:, :, None] * cov_ratio # (B*Q, Q, Q)\n",
    "    \n",
    "    # Remove the ith entry by masking ci with a boolean mask with False across\n",
    "    # the diagonal and True in the off-diagonal terms\n",
    "    mask = tf.math.logical_not(tf.cast(tf.eye(Q, dtype=tf.int32), dtype=tf.bool))\n",
    "    mask = tf.tile(mask[None, :, :], (ci.shape[0], 1, 1))\n",
    "    \n",
    "    ci = tf.ragged.boolean_mask(ci, mask).to_tensor()\n",
    "    \n",
    "    return ci\n",
    "\n",
    "\n",
    "def compute_Sigmai_matrix(Sigma_reshaped):\n",
    "    \"\"\"\n",
    "    Sigma_reshaped: tf.Tensor, shape (B*Q, Q, Q)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack tensor shape\n",
    "    BQ, Q, _ = Sigma_reshaped.shape\n",
    "    \n",
    "    Sigma_uv = tf.tile(Sigma_reshaped[:, None, :, :], (1, Q, 1, 1))\n",
    "    Sigma_iu = tf.tile(Sigma_reshaped[:, :, :, None], (1, 1, 1, Q))\n",
    "    Sigma_iv = tf.tile(Sigma_reshaped[:, :, None, :], (1, 1, Q, 1))\n",
    "    Sigma_ii = tf.linalg.diag_part(Sigma_reshaped)[:, :, None, None]\n",
    "    \n",
    "    Sigmai_whole = Sigma_uv - Sigma_iu * Sigma_iv / Sigma_ii\n",
    "    \n",
    "    def create_blocks(q):\n",
    "        \n",
    "        block1 = tf.concat(\n",
    "            [\n",
    "                Sigmai_whole[:, q, :q, :q],\n",
    "                Sigmai_whole[:, q, q+1:, :q],\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        \n",
    "        block2 = tf.concat(\n",
    "            [\n",
    "                Sigmai_whole[:, q, :q, q+1:],\n",
    "                Sigmai_whole[:, q, q+1:, q+1:],\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        \n",
    "        Sigmai_block = tf.concat([block1, block2], axis=2)\n",
    "        \n",
    "        return Sigmai_block\n",
    "    \n",
    "    Sigmai = tf.map_fn(\n",
    "        create_blocks,\n",
    "        tf.range(Q),\n",
    "        fn_output_signature=Sigmai_whole.dtype,\n",
    "    )\n",
    "    Sigmai = tf.transpose(Sigmai, perm=[1, 0, 2, 3])\n",
    "    \n",
    "    return Sigmai\n",
    "\n",
    "\n",
    "def compute_Phi(\n",
    "        ci: tf.Tensor,\n",
    "        Sigmai: tf.Tensor,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        ci: tf.Tensor, shape (B*Q, Q, Q-1)\n",
    "        Sigmai: tf.Tensor, shape (B*Q, Q, Q, Q-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack tensor shape and data type\n",
    "    BQ, Q, _, _ = Sigmai.shape\n",
    "    dtype = Sigmai.dtype\n",
    "\n",
    "    ci_reshaped = tf.reshape(ci, (BQ*Q, Q-1))\n",
    "    Sigmai_reshaped = tf.reshape(Sigmai, (BQ*Q, Q-1, Q-1))\n",
    "    \n",
    "    # Compute mean, covariance, lower and upper bounds for Phi mvn normal cdf\n",
    "    Phi_cdf_mean = tf.zeros(shape=(BQ*Q, Q-1), dtype=dtype)  # (B*Q*Q, Q)\n",
    "    Phi_cdf_cov = Sigmai_reshaped  # (B*Q*Q, Q-1, Q-1)\n",
    "    \n",
    "    Phi_cdf_upper = ci_reshaped  # (B*Q, Q-1)\n",
    "    Phi_cdf_lower = float(\"-inf\") * tf.ones_like(Phi_cdf_upper)  # (B*Q*Q, Q-1)\n",
    "    \n",
    "    # Compute multivariate cdfs\n",
    "    mvn_cdfs = mvn_cdf(\n",
    "        mean=Phi_cdf_mean,\n",
    "        cov=Phi_cdf_cov,\n",
    "        lower=Phi_cdf_lower,\n",
    "        upper=Phi_cdf_upper,\n",
    "        verbose=True,\n",
    "    )\n",
    "    mvn_cdfs = tf.reshape(mvn_cdfs, (B, Q, Q))  # (B, Q, Q)\n",
    "    \n",
    "    return mvn_cdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2408,
   "id": "ce4f2d16-8042-4113-803f-cfd5d809ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def expected_improvement(\n",
    "        mean: tf.Tensor,\n",
    "        covariance: tf.Tensor,\n",
    "        threshold: tf.Tensor,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        mean: tf.Tensor, shape (B, Q)\n",
    "        covariance: tf.Tensor, shape (B, Q, Q)\n",
    "        threshold: tf.Tensor, shape (B,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack dtype and mean shape\n",
    "    dtype = mean.dtype\n",
    "    B, Q = mean.shape\n",
    "    \n",
    "    # Compute b and m tensors\n",
    "    b, m = compute_bm(mean=mean, threshold=threshold) # (B, Q, Q), (B, Q, Q)\n",
    "        \n",
    "    # Compute Sigma\n",
    "    Sigma = compute_Sigma(covariance=covariance) # (B, Q, Q, Q)\n",
    "    \n",
    "    # Reshape all tensors, for batching\n",
    "    b_reshaped = tf.reshape(b, (B*Q, Q))\n",
    "    m_reshaped = tf.reshape(m, (B*Q, Q))\n",
    "    Sigma_reshaped = tf.reshape(Sigma, (B*Q, Q, Q))\n",
    "    \n",
    "    # Compute p tensor\n",
    "    p = compute_p(\n",
    "        m_reshaped=m_reshaped,\n",
    "        b_reshaped=b_reshaped,\n",
    "        Sigma_reshaped=Sigma_reshaped,\n",
    "    )\n",
    "        \n",
    "    # Compute ci\n",
    "    ci = compute_ci(\n",
    "        m_reshaped=m_reshaped,\n",
    "        b_reshaped=b_reshaped,\n",
    "        Sigma_reshaped=Sigma_reshaped,\n",
    "    ) # (B*Q, Q, Q-1)\n",
    "        \n",
    "    # Compute Sigma_i\n",
    "    Sigmai = compute_Sigmai_matrix(\n",
    "        Sigma_reshaped=Sigma_reshaped,\n",
    "    ) # (B*Q, Q, Q-1, Q-1)\n",
    "    \n",
    "    # Compute Q-1 multivariate CDFs\n",
    "    Phi_mvn_cdfs = compute_Phi(\n",
    "        ci=ci,\n",
    "        Sigmai=Sigmai,\n",
    "    )\n",
    "        \n",
    "    # Compute univariate cdfs\n",
    "    S_diag = tf.linalg.diag_part(Sigma)\n",
    "    normal = tfp.distributions.Normal(loc=m, scale=S_diag**0.5)\n",
    "    uvn_cdfs = tf.math.exp(normal.log_prob(b))  # (B, Q, Q)\n",
    "    \n",
    "    Sigma_diag = tf.linalg.diag_part(\n",
    "        tf.transpose(Sigma, perm=[0, 2, 1, 3])\n",
    "    )\n",
    "    Sigma_diag = tf.transpose(Sigma_diag, perm=[0, 2, 1])\n",
    "    \n",
    "    T = tf.tile(threshold[:, None], (1, Q))\n",
    "    \n",
    "    mean_T_term = (mean - T) * p\n",
    "    \n",
    "    sum_term = tf.reduce_sum(\n",
    "        Sigma_diag * uvn_cdfs * Phi_mvn_cdfs,\n",
    "        axis=2,\n",
    "    )\n",
    "    \n",
    "    qEI = tf.reduce_sum(mean_T_term + sum_term, axis=1)\n",
    "    \n",
    "    return qEI\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def debugging_monte_carlo(\n",
    "        mean: tf.Tensor,\n",
    "        covariance: tf.Tensor,\n",
    "        threshold: tf.Tensor,\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "    \n",
    "    mean = mean.numpy()\n",
    "    cov = covariance.numpy()\n",
    "    threshold = threshold.numpy()\n",
    "    \n",
    "    # Unpack dtype and mean shape\n",
    "    dtype = mean.dtype\n",
    "    B, Q = mean.shape\n",
    "    \n",
    "    # Compute b\n",
    "    b = np.zeros(shape=(B, Q, Q), dtype=dtype)\n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            for i in range(Q):\n",
    "                b[n, k, i] = - threshold[n] if k == i else 0.\n",
    "                \n",
    "    # Compute m\n",
    "    m = np.zeros(shape=(B, Q, Q), dtype=dtype)\n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            for i in range(Q):\n",
    "                m[n, k, i] = mean[n, i] - mean[n, k] if k != i else - mean[n, k]\n",
    "        \n",
    "    # Compute Sigma\n",
    "    Sigma = np.zeros(shape=(B, Q, Q, Q), dtype=dtype)\n",
    "    \n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            for i in range(Q):\n",
    "                for j in range(Q):\n",
    "                    \n",
    "                    dik = int(i != k)\n",
    "                    djk = int(j != k)\n",
    "                    \n",
    "                    Sigma[n, k, i, j] = cov[n, i, j] * dik * djk - cov[n, i, k] * dik - cov[n, j, k] * djk + cov[n, k, k]\n",
    "        \n",
    "    # Compute p\n",
    "    p = np.zeros(shape=(B, Q), dtype=dtype)\n",
    "    \n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            \n",
    "            p_cdf_mean = tf.convert_to_tensor(tf.zeros(shape=(1, Q), dtype=dtype))\n",
    "            p_cdf_cov = tf.convert_to_tensor(Sigma[n:n+1, k])\n",
    "\n",
    "            p_cdf_upper = tf.convert_to_tensor(b[n:n+1, k] - m[n:n+1, k])\n",
    "            p_cdf_lower = tf.convert_to_tensor(float(\"-inf\") * np.ones_like(p_cdf_upper))\n",
    "\n",
    "            # Compute MVN CDF\n",
    "            p[n, k] = tf.reduce_mean(\n",
    "                mc_mvn_cdf(\n",
    "                    mean=p_cdf_mean[0],\n",
    "                    cov=p_cdf_cov[0],\n",
    "                    lower=p_cdf_lower[0],\n",
    "                    upper=p_cdf_upper[0],\n",
    "                    num_samples=int(1e7),\n",
    "                ).numpy()\n",
    "            )\n",
    "        \n",
    "    # Compute c\n",
    "    c = np.zeros(shape=(B, Q, Q, Q-1), dtype=dtype)\n",
    "    \n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            for i in range(Q):\n",
    "                for j in range(Q):\n",
    "                    \n",
    "                    if i == j:\n",
    "                        continue\n",
    "                        \n",
    "                    else:\n",
    "                        l = j if j < i else j-1\n",
    "            \n",
    "                        c[n, k, i, l] = (b[n, k, j] - m[n, k, j]) - \\\n",
    "                                        (b[n, k, i] - m[n, k, i]) * Sigma[n, k, i, j] / Sigma[n, k, i, i]\n",
    "        \n",
    "        \n",
    "    # Compute Sigmai\n",
    "    Sigmai = np.zeros(shape=(B, Q, Q, Q-1, Q-1), dtype=dtype)\n",
    "    \n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            for i in range(Q):\n",
    "                for j in range(Q):\n",
    "                    for l in range(Q):\n",
    "                        \n",
    "                        if i == j or i == l:\n",
    "                            pass\n",
    "                        \n",
    "                        else:\n",
    "                            u = j if j < i else j-1\n",
    "                            v = l if l < i else l-1\n",
    "                            \n",
    "                            Sigmai[n, k, i, u, v] = Sigma[n, k, j, l] - \\\n",
    "                                                    Sigma[n, k, i, j] * Sigma[n, k, i, l] / Sigma[n, k, i, i]\n",
    "    \n",
    "    Phi = np.zeros(shape=(B, Q, Q), dtype=dtype)\n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            for i in range(Q):\n",
    "                Phi[n, k, i] = norm(loc=0., scale=Sigmai[n, k, i, 0, 0]**0.5).cdf(c[n, k, i, 0])\n",
    "    \n",
    "    uvn = np.zeros(shape=(B, Q, Q), dtype=dtype)\n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            for i in range(Q):\n",
    "                uvn[n, k, i] = norm(loc=m[n, k, i], scale=Sigma[n, k, i, i]**0.5).cdf(b[n, k, i])\n",
    "    \n",
    "    \n",
    "    qEI = np.zeros(shape=(B,), dtype=dtype)\n",
    "    for n in range(B):\n",
    "        for k in range(Q):\n",
    "            \n",
    "            qEI[n] = qEI[n] + (mean[n, k] - threshold[n]) * p[n, k]\n",
    "            \n",
    "            for i in range(Q):\n",
    "                qEI[n] = qEI[n] + Sigma[n, k, i, k] * uvn[n, k, i] * Phi[n, k, i]\n",
    "        \n",
    "    return list(map(tf.convert_to_tensor, [b, m, Sigma, p, c, Sigmai, Phi, uvn, qEI]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2447,
   "id": "956ae45e-da3e-407a-876e-784f2984e763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.76465349, 0.41053497, 1.02134702, 1.06179615])>"
      ]
     },
     "execution_count": 2447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "B = 4\n",
    "Q = 5\n",
    "\n",
    "# mean = tf.random.uniform(shape=(B, Q), dtype=dtype)\n",
    "mean = tf.zeros(shape=(B, Q), dtype=dtype)\n",
    "rand = tf.random.uniform((B, Q, Q), dtype=dtype) / Q**0.5\n",
    "covariance = 1e-1 * tf.matmul(rand, rand, transpose_b=True) + tf.eye(Q, dtype=dtype)[None, ...]\n",
    "\n",
    "threshold = tf.random.uniform((B,), dtype=dtype)\n",
    "\n",
    "expected_improvement(mean=mean, covariance=covariance, threshold=threshold, verbose=False)\n",
    "\n",
    "# %timeit _ = expected_improvement(mean=mean, covariance=covariance, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2449,
   "id": "c74c8088-d3c8-4ff3-ac64-b16af68ec70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcei(\n",
    "        mean: tf.Tensor,\n",
    "        covariance: tf.Tensor,\n",
    "        threshold: tf.Tensor,\n",
    "        num_samples: int = 1000000,\n",
    "    ):\n",
    "    \n",
    "    covariance = covariance + 1e-6 * tf.eye(covariance.shape[1], dtype=covariance.dtype)\n",
    "    \n",
    "    mvn = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "        loc=mean,\n",
    "        covariance_matrix=covariance,\n",
    "    )\n",
    "    \n",
    "    samples = mvn.sample(sample_shape=[num_samples])\n",
    "    \n",
    "    tiled_threshold = tf.tile(\n",
    "        threshold[None, :, None],\n",
    "        (num_samples, 1, 1),\n",
    "    )\n",
    "    \n",
    "    print(f\"{samples.shape=} {tiled_threshold.shape=}\")\n",
    "    \n",
    "    samples_and_thresholds = tf.concat(\n",
    "        [samples, tiled_threshold], axis=-1\n",
    "    )\n",
    "    maxima = tf.reduce_max(samples_and_thresholds, axis=-1)\n",
    "    improvements = maxima - threshold[None, :]\n",
    "    \n",
    "    if tf.reduce_any(tf.less(improvements, tf.zeros_like(improvements))):\n",
    "        raise Exception\n",
    "    \n",
    "    return tf.reduce_mean(improvements, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2450,
   "id": "ace5d6cb-a079-4729-b2ef-5b68be21fdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples.shape=TensorShape([1000000, 4, 5]) tiled_threshold.shape=TensorShape([1000000, 4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float64, numpy=array([0.76701407, 0.41131783, 1.02377429, 1.06344876])>"
      ]
     },
     "execution_count": 2450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcei(mean=mean, covariance=covariance, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fe5c05-8489-4e90-95ee-5bbaf011443c",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "- Write down qEI derivation following Ginsbourger.\n",
    "- Implement qEI without batching using for-loops.\n",
    "- Look at values using above implentation, with special values for mean, covariance and threshold, for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5df6fd-dead-4daf-98a4-ca26edf0ae09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-trieste",
   "language": "python",
   "name": "venv-trieste"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
